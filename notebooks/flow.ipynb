{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter, deque\n",
    "import urllib.request\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_seconds_milliseconds(seconds: float) -> float:\n",
    "    return seconds * 1000\n",
    "\n",
    "def duration(start: float, end: float) -> float:\n",
    "    return end - start\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Download Speed](https://cses.fi/problemset/task/1694)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowEdge:\n",
    "    def __init__(self, src: int, dst: int, cap: int):\n",
    "        self.src = src # source node\n",
    "        self.dst = dst # destination node\n",
    "        self.cap = cap\n",
    "\n",
    "class FordFulkersonMaxFlow:\n",
    "    \"\"\"\n",
    "    Ford-Fulkerson algorithm \n",
    "    - pluggable augmenting path finding algorithms\n",
    "    - residual graph\n",
    "    - bottleneck capacity\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int, edges: List[Tuple[int, int, int]]):\n",
    "        self.size = n\n",
    "        self.edges = edges\n",
    "\n",
    "    def build(self, n: int, edges: List[Tuple[int, int, int]]) -> None:\n",
    "        self.flowedges = []\n",
    "        self.adj_list = {}\n",
    "        self.delta = cnt = 0\n",
    "        for u, v, cap in edges:\n",
    "\n",
    "            if u not in self.adj_list:\n",
    "                self.adj_list[u] = Counter()\n",
    "            self.adj_list[u][v] += cap\n",
    "            if v not in self.adj_list:\n",
    "                self.adj_list[v] = Counter()\n",
    "            self.delta = max(self.delta, cap)\n",
    "        highest_bit_set = self.delta.bit_length() - 1\n",
    "        self.delta = 1 << highest_bit_set\n",
    "\n",
    "    def main_dfs(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while True:\n",
    "            self.reset()\n",
    "            cur_flow = self.dfs(source, sink, math.inf)\n",
    "            if cur_flow == 0:\n",
    "                break\n",
    "            maxflow += cur_flow\n",
    "        return maxflow\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.parents = [-1] * self.size\n",
    "\n",
    "    def dfs(self, node: int, sink: int, flow: int) -> int:\n",
    "        if node == sink:\n",
    "            return flow\n",
    "        self.parents[node] = 1\n",
    "        cap = self.adj_list[node]\n",
    "        for nei, cap in cap.items():\n",
    "            if self.parents[nei] == -1 and cap > 0:\n",
    "                cur_flow = self.dfs(nei, sink, min(flow, cap))\n",
    "                if cur_flow > 0:\n",
    "                    self.adj_list[node][nei] -= cur_flow\n",
    "                    self.adj_list[nei][node] += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "    \n",
    "    def main_edmonds_karp(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while True:\n",
    "            self.reset()\n",
    "            cur_flow = self.edmonds_karp(source, sink)\n",
    "            if cur_flow == 0:\n",
    "                break\n",
    "            maxflow += cur_flow\n",
    "        return maxflow\n",
    "\n",
    "    def edmonds_karp(self, source: int, sink: int) -> int:\n",
    "        queue = deque([(source, math.inf)])\n",
    "        self.parents[source] = -2\n",
    "        while queue:\n",
    "            node, flow = queue.popleft()\n",
    "            if node == sink:\n",
    "                break\n",
    "            capacity = self.adj_list[node]\n",
    "            for nei, cap in capacity.items():\n",
    "                if self.parents[nei] == -1 and cap > 0:\n",
    "                    self.parents[nei] = node\n",
    "                    queue.append((nei, min(flow, cap)))\n",
    "        if node == sink:\n",
    "            while node != source:\n",
    "                parent = self.parents[node]\n",
    "                self.adj_list[parent][node] -= flow\n",
    "                self.adj_list[node][parent] += flow # residual edge\n",
    "                node = parent\n",
    "            return flow\n",
    "        return 0\n",
    "\n",
    "    def main_capacity_scaling(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while self.delta > 0:\n",
    "            while True:\n",
    "                self.reset()\n",
    "                cur_flow = self.capacity_scaling(source, sink, math.inf)\n",
    "                if cur_flow == 0:\n",
    "                    break\n",
    "                maxflow += cur_flow\n",
    "            self.delta >>= 1\n",
    "        return maxflow\n",
    "\n",
    "    def capacity_scaling(self, source: int, sink: int, flow: int) -> int:\n",
    "        if source == sink:\n",
    "            return flow\n",
    "        self.parents[source] = 1\n",
    "        capacity = self.adj_list[source]\n",
    "        for nei, cap in capacity.items():\n",
    "            if self.parents[nei] == -1 and cap >= self.delta:\n",
    "                cur_flow = self.capacity_scaling(nei, sink, min(flow, cap))\n",
    "                if cur_flow > 0:\n",
    "                    self.adj_list[source][nei] -= cur_flow\n",
    "                    self.adj_list[nei][source] += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "\n",
    "    def dinics_bfs(self, source: int, sink: int) -> bool:\n",
    "        self.distances = [-1] * self.size\n",
    "        self.distances[source] = 0\n",
    "        queue = deque([source])\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            for nei, cap in self.adj_list[node].items():\n",
    "                if self.distances[nei] == -1 and cap > 0:\n",
    "                    self.distances[nei] = self.distances[node] + 1\n",
    "                    queue.append(nei)\n",
    "        return self.distances[sink] != -1\n",
    "\n",
    "    def dinics_dfs(self, node: int, sink: int, flow: int) -> int:\n",
    "        if flow == 0: return 0\n",
    "        if node == sink: return flow\n",
    "        for nei, cap in self.adj_list[node].items():\n",
    "            if self.distances[nei] == self.distances[node] + 1 and cap > 0:\n",
    "                cur_flow = self.dinics_dfs(nei, sink, min(flow, cap))\n",
    "                if cur_flow > 0:\n",
    "                    self.adj_list[node][nei] -= cur_flow\n",
    "                    self.adj_list[nei][node] += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "\n",
    "    def main_dinics(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while self.dinics_bfs(source, sink):\n",
    "            self.reset()\n",
    "            while True:\n",
    "                cur_flow = self.dinics_dfs(source, sink, math.inf)\n",
    "                if cur_flow == 0:\n",
    "                    break\n",
    "                maxflow += cur_flow\n",
    "        return maxflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://cses.fi/file/acec992e42fe3462f07114ad2d5f7ce9ff27434922e9b52f39006310ca79d019/1/1/', \\\n",
    "    'https://cses.fi/file/558f035a5dce8931e19371bda522b5a81d28a9a1a1835a6205e566ca9de324c8/1/1/', \\\n",
    "    'https://cses.fi/file/9201642e4901d251a2c18f26429a67089a018a07cd3aa6025cb5fd12d4f88126/1/1/', \\\n",
    "    'https://cses.fi/file/654fbbbac2b61ff15187c1d399394ea7e27b05b3dddf32bdba1bb1c6708e3593/1/1/', \\\n",
    "    'https://cses.fi/file/8286fe339a5312417d20620138dec793deb78cd8960f33ddc4f521982e71f046/1/1/', \\\n",
    "    'https://cses.fi/file/297a2fce46a4102cbd86bea796751acd566fcae258aa00b62d34f5436e441b27/1/1/', \\\n",
    "    'https://cses.fi/file/f1cb0fbf03699e8e91a47846d49e084dae8ec899186d7766461383b5bf562452/1/1/', \\\n",
    "    'https://cses.fi/file/d31400a9196af8d78037127201e471353fcd1f5aaecc9939ea4740a054559c0f/1/1/', \\\n",
    "    'https://cses.fi/file/963201f693af2a27f8d43a78a6213b938576971e71fd5270ad62b538cae9cd47/1/1/', \\\n",
    "    'https://cses.fi/file/9b1a8c894a16cc3228c663a38b764156f7f47183b2f7b206866f935d693dbae7/1/1/', \\\n",
    "    'https://cses.fi/file/e27523c04940efd4cddc19cb7ad99a65635c2fb88cf1c86a7492e08089e8c942/1/1/', \\\n",
    "    'https://cses.fi/file/a09e3665a05e05a0f4e6d590b271ba889bed02c5aae69522d38d8bf1c62aa371/1/1/', \\\n",
    "    'https://cses.fi/file/ec19840ed099c8e55fd77bf40b1cf4f6fdbd43c0a63c74dfe736de4d38cb67cd/1/1/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testcase: 0 in 4.369199996290263e-05 seconds\n",
      "Finished testcase: 1 in 9.185000089928508e-05 seconds\n",
      "Finished testcase: 2 in 0.00015807799900358077 seconds\n",
      "Finished testcase: 3 in 2.5332999939564615e-05 seconds\n",
      "Finished testcase: 4 in 0.002146345001165173 seconds\n",
      "Finished testcase: 5 in 0.007383099999060505 seconds\n",
      "Finished testcase: 6 in 0.01204634699934104 seconds\n",
      "Finished testcase: 7 in 7.481900138373021e-05 seconds\n",
      "Finished testcase: 8 in 0.00011746599921025336 seconds\n",
      "Finished testcase: 9 in 0.00013515799946617335 seconds\n",
      "Finished testcase: 10 in 0.004136886000196682 seconds\n",
      "Finished testcase: 11 in 0.00010916400060523301 seconds\n",
      "Finished testcase: 12 in 0.013471493999531958 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using the dfs implementation as the base case, it was tested to work in the online judge.\n",
    "\"\"\"\n",
    "results = [0]*len(urls)\n",
    "for i, url in enumerate(urls):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    for j, line in enumerate(map(lambda line: line.decode('utf-8').strip('\\n'), data)):\n",
    "        if j == 0:\n",
    "            n, m = map(int, line.split())\n",
    "            edges = []\n",
    "        else:\n",
    "            u, v, cap = map(int, line.split())\n",
    "            edges.append((u - 1, v - 1, cap))\n",
    "    start_time = time.perf_counter()\n",
    "    mf = FordFulkersonMaxFlow(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    results[i] = mf\n",
    "    print(f'Finished testcase: {i} in {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, url in enumerate(urls):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    for j, line in enumerate(map(lambda line: line.decode('utf-8').strip('\\n'), data)):\n",
    "        if j == 0:\n",
    "            n, m = map(int, line.split())\n",
    "            edges = []\n",
    "        else:\n",
    "            u, v, cap = map(int, line.split())\n",
    "            edges.append((u - 1, v - 1, cap))\n",
    "    start_time = time.perf_counter()\n",
    "    mf = FordFulkersonMaxFlow(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    assert mf == results[i], f'Failed on testcase: {i}'\n",
    "    print(f'Finished testcase: {i} in {end_time - start_time} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 0 passed\n",
      "dfs: 0.03157599894620944 milliseconds\n",
      "edmonds-karp: 0.01743299981171731 milliseconds\n",
      "capacity scaling: 0.019139999494655058 milliseconds\n",
      "dinics: 0.019088000044575892 milliseconds\n",
      "Test case 1 passed\n",
      "dfs: 0.08477200026391074 milliseconds\n",
      "edmonds-karp: 0.04752400127472356 milliseconds\n",
      "capacity scaling: 0.04356200042821001 milliseconds\n",
      "dinics: 0.04602899934980087 milliseconds\n",
      "Test case 2 passed\n",
      "dfs: 0.06654299977526534 milliseconds\n",
      "edmonds-karp: 0.0345779990311712 milliseconds\n",
      "capacity scaling: 0.0692449993948685 milliseconds\n",
      "dinics: 0.032698999348212965 milliseconds\n",
      "Test case 3 passed\n",
      "dfs: 0.07162099973356817 milliseconds\n",
      "edmonds-karp: 0.030152999897836708 milliseconds\n",
      "capacity scaling: 0.04189700121060014 milliseconds\n",
      "dinics: 0.02439600029902067 milliseconds\n",
      "Test case 4 passed\n",
      "dfs: 2.622571999381762 milliseconds\n",
      "edmonds-karp: 1.964944000064861 milliseconds\n",
      "capacity scaling: 2.0339249986136565 milliseconds\n",
      "dinics: 2.024875999268261 milliseconds\n",
      "Test case 5 passed\n",
      "dfs: 6.746938999640406 milliseconds\n",
      "edmonds-karp: 4.215986999042798 milliseconds\n",
      "capacity scaling: 4.797696999958134 milliseconds\n",
      "dinics: 4.426231000252301 milliseconds\n",
      "Test case 6 passed\n",
      "dfs: 14.084679000006872 milliseconds\n",
      "edmonds-karp: 5.338969000149518 milliseconds\n",
      "capacity scaling: 11.243589999139658 milliseconds\n",
      "dinics: 6.43846699858841 milliseconds\n",
      "Test case 7 passed\n",
      "dfs: 0.08465999962936621 milliseconds\n",
      "edmonds-karp: 0.04445200102054514 milliseconds\n",
      "capacity scaling: 0.03219599966541864 milliseconds\n",
      "dinics: 0.041573000999051146 milliseconds\n",
      "Test case 8 passed\n",
      "dfs: 0.13435599976219237 milliseconds\n",
      "edmonds-karp: 0.0897999998414889 milliseconds\n",
      "capacity scaling: 0.07407200064335484 milliseconds\n",
      "dinics: 0.08454099952359684 milliseconds\n",
      "Test case 9 passed\n",
      "dfs: 0.04298800013202708 milliseconds\n",
      "edmonds-karp: 0.030760998924961314 milliseconds\n",
      "capacity scaling: 0.024931001462391578 milliseconds\n",
      "dinics: 0.037316998714231886 milliseconds\n",
      "Test case 10 passed\n",
      "dfs: 1.7212120001204312 milliseconds\n",
      "edmonds-karp: 1.3678499999514315 milliseconds\n",
      "capacity scaling: 1.4325230004033074 milliseconds\n",
      "dinics: 1.14961500003119 milliseconds\n",
      "Test case 11 passed\n",
      "dfs: 0.09587800013832748 milliseconds\n",
      "edmonds-karp: 0.07138999899325427 milliseconds\n",
      "capacity scaling: 0.05500000042957254 milliseconds\n",
      "dinics: 0.08348499977728352 milliseconds\n",
      "Test case 12 passed\n",
      "dfs: 17.25488400006725 milliseconds\n",
      "edmonds-karp: 75.80916500046442 milliseconds\n",
      "capacity scaling: 8.481142000164255 milliseconds\n",
      "dinics: 17.285809000895824 milliseconds\n",
      "CPU times: user 529 ms, sys: 19.4 ms, total: 548 ms\n",
      "Wall time: 8.73 s\n"
     ]
    }
   ],
   "source": [
    "for i, url in enumerate(urls):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    for j, line in enumerate(map(lambda line: line.decode('utf-8').strip('\\n'), data)):\n",
    "        if j == 0:\n",
    "            n, m = map(int, line.split())\n",
    "            edges = []\n",
    "        else:\n",
    "            u, v, cap = map(int, line.split())\n",
    "            edges.append((u - 1, v - 1, cap))\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dfs = FordFulkersonMaxFlow(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dfs = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_edmonds = FordFulkersonMaxFlow(n, edges).main_edmonds_karp(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_edmonds_karp = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_cp_scaling = FordFulkersonMaxFlow(n, edges).main_capacity_scaling(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_cp_scaling = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dinics = FordFulkersonMaxFlow(n, edges).main_dinics(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dinics = duration(start_time, end_time)\n",
    "    assert mf_edmonds == results[i], f'Failed on testcase: {i}, output: {mf_edmonds}, expected: {results[i]} for edmonds-karp algorithm'\n",
    "    assert mf_cp_scaling == results[i], f'Failed on testcase: {i}, output: {mf_cp_scaling}, expected: {results[i]} for capacity scaling algorithm'\n",
    "    assert mf_dinics == results[i], f'Failed on testcase: {i}, output: {mf_dinics}, expected: {results[i]} for dinics algorithm'\n",
    "    print(f'Test case {i} passed')\n",
    "    print(f'dfs: {conv_seconds_milliseconds(duration_dfs)} milliseconds')\n",
    "    print(f'edmonds-karp: {conv_seconds_milliseconds(duration_edmonds_karp)} milliseconds')\n",
    "    print(f'capacity scaling: {conv_seconds_milliseconds(duration_cp_scaling)} milliseconds')\n",
    "    print(f'dinics: {conv_seconds_milliseconds(duration_dinics)} milliseconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, url in enumerate(urls):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    for j, line in enumerate(map(lambda line: line.decode('utf-8').strip('\\n'), data)):\n",
    "        if j == 0:\n",
    "            n, m = map(int, line.split())\n",
    "            edges = []\n",
    "        else:\n",
    "            u, v, cap = map(int, line.split())\n",
    "            edges.append((u - 1, v - 1, cap))\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dfs = FordFulkersonMaxFlow(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dfs = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_edmonds = FordFulkersonMaxFlow(n, edges).main_edmonds_karp(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_edmonds_karp = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_cp_scaling = FordFulkersonMaxFlow(n, edges).main_capacity_scaling(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_cp_scaling = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dinics = FordFulkersonMaxFlow(n, edges).main_dinics(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dinics = duration(start_time, end_time)\n",
    "    assert mf_edmonds == results[i], f'Failed on testcase: {i}, output: {mf_edmonds}, expected: {results[i]} for edmonds-karp algorithm'\n",
    "    assert mf_cp_scaling == results[i], f'Failed on testcase: {i}, output: {mf_cp_scaling}, expected: {results[i]} for capacity scaling algorithm'\n",
    "    assert mf_dinics == results[i], f'Failed on testcase: {i}, output: {mf_dinics}, expected: {results[i]} for dinics algorithm'\n",
    "    print(f'Test case {i} passed')\n",
    "    print(f'dfs: {conv_seconds_milliseconds(duration_dfs)} milliseconds')\n",
    "    print(f'edmonds-karp: {conv_seconds_milliseconds(duration_edmonds_karp)} milliseconds')\n",
    "    print(f'capacity scaling: {conv_seconds_milliseconds(duration_cp_scaling)} milliseconds')\n",
    "    print(f'dinics: {conv_seconds_milliseconds(duration_dinics)} milliseconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05a440cbc0a4d5663111a9b3b9ea59349399813ac6e64ad16052767f7ba4c947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
