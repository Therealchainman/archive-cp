{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter, deque\n",
    "import urllib.request\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_seconds_milliseconds(seconds: float) -> float:\n",
    "    return seconds * 1000\n",
    "\n",
    "def duration(start: float, end: float) -> float:\n",
    "    return end - start\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FordFulkeron algorithm for maximum flow problem \n",
    "- pluggable augmenting path finding algorithms\n",
    "- residual graph\n",
    "- bottleneck capacity\n",
    "- merge parallele edges by sum of all parallel edges capacities\n",
    "- depth first search\n",
    "- Edmonds-Karp algorithm\n",
    "- capacity scaling algorithm\n",
    "- dinics algorithm\n",
    "\"\"\"\n",
    "class FordFulkersonMaxFlowV1:\n",
    "    \"\"\"\n",
    "    Ford-Fulkerson algorithm \n",
    "    - pluggable augmenting path finding algorithms\n",
    "    - residual graph\n",
    "    - bottleneck capacity\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int, edges: List[Tuple[int, int, int]]):\n",
    "        self.size = n\n",
    "        self.edges = edges\n",
    "\n",
    "    def build(self, n: int, edges: List[Tuple[int, int, int]]) -> None:\n",
    "        self.adj_list = {}\n",
    "        self.delta = cnt = 0\n",
    "        for u, v, cap in edges:\n",
    "            if u not in self.adj_list:\n",
    "                self.adj_list[u] = Counter()\n",
    "            self.adj_list[u][v] += cap\n",
    "            if v not in self.adj_list:\n",
    "                self.adj_list[v] = Counter()\n",
    "            self.delta = max(self.delta, self.adj_list[u][v])\n",
    "        highest_bit_set = self.delta.bit_length() - 1\n",
    "        self.delta = 1 << highest_bit_set\n",
    "\n",
    "    def main_dfs(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while True:\n",
    "            self.reset()\n",
    "            cur_flow = self.dfs(source, sink, math.inf)\n",
    "            if cur_flow == 0:\n",
    "                break\n",
    "            maxflow += cur_flow\n",
    "        return maxflow\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.parents = [-1] * self.size\n",
    "\n",
    "    def dfs(self, node: int, sink: int, flow: int) -> int:\n",
    "        if node == sink:\n",
    "            return flow\n",
    "        self.parents[node] = 1\n",
    "        cap = self.adj_list[node]\n",
    "        for nei, cap in cap.items():\n",
    "            if self.parents[nei] == -1 and cap > 0:\n",
    "                cur_flow = self.dfs(nei, sink, min(flow, cap))\n",
    "                if cur_flow > 0:\n",
    "                    self.adj_list[node][nei] -= cur_flow\n",
    "                    self.adj_list[nei][node] += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "    \n",
    "    def main_edmonds_karp(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while True:\n",
    "            self.reset()\n",
    "            cur_flow = self.edmonds_karp(source, sink)\n",
    "            if cur_flow == 0:\n",
    "                break\n",
    "            maxflow += cur_flow\n",
    "        return maxflow\n",
    "\n",
    "    def edmonds_karp(self, source: int, sink: int) -> int:\n",
    "        queue = deque([(source, math.inf)])\n",
    "        self.parents[source] = -2\n",
    "        while queue:\n",
    "            node, flow = queue.popleft()\n",
    "            if node == sink:\n",
    "                break\n",
    "            capacity = self.adj_list[node]\n",
    "            for nei, cap in capacity.items():\n",
    "                if self.parents[nei] == -1 and cap > 0:\n",
    "                    self.parents[nei] = node\n",
    "                    queue.append((nei, min(flow, cap)))\n",
    "        if node == sink:\n",
    "            while node != source:\n",
    "                parent = self.parents[node]\n",
    "                self.adj_list[parent][node] -= flow\n",
    "                self.adj_list[node][parent] += flow # residual edge\n",
    "                node = parent\n",
    "            return flow\n",
    "        return 0\n",
    "\n",
    "    def main_capacity_scaling(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while self.delta > 0:\n",
    "            while True:\n",
    "                self.reset()\n",
    "                cur_flow = self.capacity_scaling(source, sink, math.inf)\n",
    "                if cur_flow == 0:\n",
    "                    break\n",
    "                maxflow += cur_flow\n",
    "            self.delta >>= 1\n",
    "        return maxflow\n",
    "\n",
    "    def capacity_scaling(self, source: int, sink: int, flow: int) -> int:\n",
    "        if source == sink:\n",
    "            return flow\n",
    "        self.parents[source] = 1\n",
    "        capacity = self.adj_list[source]\n",
    "        for nei, cap in capacity.items():\n",
    "            if self.parents[nei] == -1 and cap >= self.delta:\n",
    "                cur_flow = self.capacity_scaling(nei, sink, min(flow, cap))\n",
    "                if cur_flow > 0:\n",
    "                    self.adj_list[source][nei] -= cur_flow\n",
    "                    self.adj_list[nei][source] += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "\n",
    "    def dinics_bfs(self, source: int, sink: int) -> bool:\n",
    "        self.distances = [-1] * self.size\n",
    "        self.distances[source] = 0\n",
    "        queue = deque([source])\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            for nei, cap in self.adj_list[node].items():\n",
    "                if self.distances[nei] == -1 and cap > 0:\n",
    "                    self.distances[nei] = self.distances[node] + 1\n",
    "                    queue.append(nei)\n",
    "        return self.distances[sink] != -1\n",
    "\n",
    "    def dinics_dfs(self, node: int, sink: int, flow: int) -> int:\n",
    "        if flow == 0: return 0\n",
    "        if node == sink: return flow\n",
    "        for nei, cap in self.adj_list[node].items():\n",
    "            if self.distances[nei] == self.distances[node] + 1 and cap > 0:\n",
    "                cur_flow = self.dinics_dfs(nei, sink, min(flow, cap))\n",
    "                if cur_flow > 0:\n",
    "                    self.adj_list[node][nei] -= cur_flow\n",
    "                    self.adj_list[nei][node] += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "\n",
    "    def main_dinics(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while self.dinics_bfs(source, sink):\n",
    "            self.reset()\n",
    "            while True:\n",
    "                cur_flow = self.dinics_dfs(source, sink, math.inf)\n",
    "                if cur_flow == 0:\n",
    "                    break\n",
    "                maxflow += cur_flow\n",
    "        return maxflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FordFulkeron algorithm for maximum flow problem \n",
    "- pluggable augmenting path finding algorithms\n",
    "- residual graph\n",
    "- bottleneck capacity\n",
    "- flow edge class\n",
    "- depth first search\n",
    "- Edmonds-Karp algorithm\n",
    "- capacity scaling algorithm\n",
    "- dinics algorithm\n",
    "-- deadend elimination\n",
    "\"\"\"\n",
    "class FlowEdge:\n",
    "    def __init__(self, src: int, dst: int, cap: int):\n",
    "        self.src = src # source node\n",
    "        self.dst = dst # destination node\n",
    "        self.cap = cap\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'source node: {self.src}, destination node: {self.dst}, capacity: {self.cap} ======'\n",
    "\n",
    "class FordFulkersonMaxFlowV2:\n",
    "    \"\"\"\n",
    "    Ford-Fulkerson algorithm \n",
    "    - pluggable augmenting path finding algorithms\n",
    "    - residual graph\n",
    "    - bottleneck capacity\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int, edges: List[Tuple[int, int, int]]):\n",
    "        self.size = n\n",
    "        self.edges = edges\n",
    "\n",
    "    def build(self, n: int, edges: List[Tuple[int, int, int]]) -> None:\n",
    "        self.flowedges = []\n",
    "        self.adj_list = {}\n",
    "        self.delta = 0\n",
    "        for u, v, cap in edges:\n",
    "            self.flowedges.append(FlowEdge(u, v, cap))\n",
    "            if u not in self.adj_list:\n",
    "                self.adj_list[u] = []\n",
    "            self.adj_list[u].append(len(self.flowedges) - 1)\n",
    "            self.flowedges.append(FlowEdge(v, u, 0)) # residual edge\n",
    "            if v not in self.adj_list:\n",
    "                self.adj_list[v] = []\n",
    "            self.adj_list[v].append(len(self.flowedges) - 1)\n",
    "            self.delta = max(self.delta, cap)\n",
    "        highest_bit_set = self.delta.bit_length() - 1\n",
    "        self.delta = 1 << highest_bit_set\n",
    "\n",
    "    def main_dfs(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while True:\n",
    "            self.reset()\n",
    "            cur_flow = self.dfs(source, sink, math.inf)\n",
    "            if cur_flow == 0:\n",
    "                break\n",
    "            maxflow += cur_flow\n",
    "        return maxflow\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.vis = [0] * self.size\n",
    "\n",
    "    def neighborhood(self, node: int) -> List[int]:\n",
    "        return (i for i in self.adj_list[node])\n",
    "\n",
    "    def dfs(self, node: int, sink: int, flow: int) -> int:\n",
    "        if node == sink:\n",
    "            return flow\n",
    "        self.vis[node] = 1\n",
    "        for index in self.neighborhood(node):\n",
    "            nei = self.flowedges[index]\n",
    "            if self.vis[nei.dst] == 0 and nei.cap > 0:\n",
    "                cur_flow = self.dfs(nei.dst, sink, min(flow, nei.cap))\n",
    "                if cur_flow > 0:\n",
    "                    nei.cap -= cur_flow\n",
    "                    self.flowedges[index ^ 1].cap += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "    \n",
    "    def main_edmonds_karp(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while True:\n",
    "            self.reset()\n",
    "            self.parents = [-1] * len(self.flowedges)\n",
    "            cur_flow = self.edmonds_karp(source, sink)\n",
    "            if cur_flow == 0:\n",
    "                break\n",
    "            maxflow += cur_flow\n",
    "        return maxflow\n",
    "\n",
    "    def edmonds_karp(self, source: int, sink: int) -> int:\n",
    "        queue = deque([(source, math.inf, -1)])\n",
    "        self.vis[source] = 1\n",
    "        while queue:\n",
    "            node, flow, prev_index = queue.popleft()\n",
    "            if node == sink:\n",
    "                break\n",
    "            for index in self.neighborhood(node):\n",
    "                nei = self.flowedges[index]\n",
    "                if self.vis[nei.dst] == 0 and nei.cap > 0:\n",
    "                    self.vis[nei.dst] = 1\n",
    "                    self.parents[index] = prev_index\n",
    "                    queue.append((nei.dst, min(flow, nei.cap), index))\n",
    "        if node == sink:\n",
    "            while prev_index != -1:\n",
    "                parent_index = self.parents[prev_index]\n",
    "                self.flowedges[prev_index].cap -= flow\n",
    "                self.flowedges[prev_index^1].cap += flow # residual edge\n",
    "                prev_index = parent_index\n",
    "            return flow\n",
    "        return 0\n",
    "\n",
    "    def main_capacity_scaling(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while self.delta > 0:\n",
    "            while True:\n",
    "                self.reset()\n",
    "                cur_flow = self.capacity_scaling(source, sink, math.inf)\n",
    "                if cur_flow == 0:\n",
    "                    break\n",
    "                maxflow += cur_flow\n",
    "            self.delta >>= 1\n",
    "        return maxflow\n",
    "\n",
    "    def capacity_scaling(self, node: int, sink: int, flow: int) -> int:\n",
    "        if node == sink:\n",
    "            return flow\n",
    "        self.vis[node] = 1\n",
    "        for index in self.neighborhood(node):\n",
    "            nei = self.flowedges[index]\n",
    "            if self.vis[nei.dst] == 0 and nei.cap >= self.delta:\n",
    "                cur_flow = self.capacity_scaling(nei.dst, sink, min(flow, nei.cap))\n",
    "                if cur_flow > 0:\n",
    "                    nei.cap -= cur_flow\n",
    "                    self.flowedges[index ^ 1].cap += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "\n",
    "    def dinics_bfs(self, source: int, sink: int) -> bool:\n",
    "        self.distances = [-1] * self.size\n",
    "        self.distances[source] = 0\n",
    "        queue = deque([source])\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            for index in self.neighborhood(node):\n",
    "                nei = self.flowedges[index]\n",
    "                if self.distances[nei.dst] == -1 and nei.cap > 0:\n",
    "                    self.distances[nei.dst] = self.distances[node] + 1\n",
    "                    queue.append(nei.dst)\n",
    "        return self.distances[sink] != -1\n",
    "\n",
    "    def dinics_dfs(self, node: int, sink: int, flow: int) -> int:\n",
    "        if flow == 0: return 0\n",
    "        if node == sink: return flow\n",
    "        while self.ptr[node] < len(self.adj_list[node]):\n",
    "            index = self.adj_list[node][self.ptr[node]]\n",
    "            self.ptr[node] += 1\n",
    "            nei = self.flowedges[index]\n",
    "            if self.distances[nei.dst] == self.distances[node] + 1 and nei.cap > 0:\n",
    "                cur_flow = self.dinics_dfs(nei.dst, sink, min(flow, nei.cap))\n",
    "                if cur_flow > 0:\n",
    "                    nei.cap -= cur_flow\n",
    "                    self.flowedges[index ^ 1].cap += cur_flow\n",
    "                    return cur_flow\n",
    "        return 0\n",
    "\n",
    "    def main_dinics(self, source: int, sink: int) -> int:\n",
    "        self.build(self.size, self.edges)\n",
    "        maxflow = 0\n",
    "        while self.dinics_bfs(source, sink):\n",
    "            self.reset()\n",
    "            self.ptr = [0] * self.size # pointer to the next edge to be processed (optimizes for dead ends)\n",
    "            while True:\n",
    "                cur_flow = self.dinics_dfs(source, sink, math.inf)\n",
    "                if cur_flow == 0:\n",
    "                    break\n",
    "                maxflow += cur_flow\n",
    "        return maxflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Download Speed](https://cses.fi/problemset/task/1694/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://cses.fi/file/acec992e42fe3462f07114ad2d5f7ce9ff27434922e9b52f39006310ca79d019/1/1/', \\\n",
    "    'https://cses.fi/file/558f035a5dce8931e19371bda522b5a81d28a9a1a1835a6205e566ca9de324c8/1/1/', \\\n",
    "    'https://cses.fi/file/9201642e4901d251a2c18f26429a67089a018a07cd3aa6025cb5fd12d4f88126/1/1/', \\\n",
    "    'https://cses.fi/file/654fbbbac2b61ff15187c1d399394ea7e27b05b3dddf32bdba1bb1c6708e3593/1/1/', \\\n",
    "    'https://cses.fi/file/8286fe339a5312417d20620138dec793deb78cd8960f33ddc4f521982e71f046/1/1/', \\\n",
    "    'https://cses.fi/file/297a2fce46a4102cbd86bea796751acd566fcae258aa00b62d34f5436e441b27/1/1/', \\\n",
    "    'https://cses.fi/file/f1cb0fbf03699e8e91a47846d49e084dae8ec899186d7766461383b5bf562452/1/1/', \\\n",
    "    'https://cses.fi/file/d31400a9196af8d78037127201e471353fcd1f5aaecc9939ea4740a054559c0f/1/1/', \\\n",
    "    'https://cses.fi/file/963201f693af2a27f8d43a78a6213b938576971e71fd5270ad62b538cae9cd47/1/1/', \\\n",
    "    'https://cses.fi/file/9b1a8c894a16cc3228c663a38b764156f7f47183b2f7b206866f935d693dbae7/1/1/', \\\n",
    "    'https://cses.fi/file/e27523c04940efd4cddc19cb7ad99a65635c2fb88cf1c86a7492e08089e8c942/1/1/', \\\n",
    "    'https://cses.fi/file/a09e3665a05e05a0f4e6d590b271ba889bed02c5aae69522d38d8bf1c62aa371/1/1/', \\\n",
    "    'https://cses.fi/file/ec19840ed099c8e55fd77bf40b1cf4f6fdbd43c0a63c74dfe736de4d38cb67cd/1/1/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the dfs implementation as the base case, it was tested to work in the online judge.\n",
    "\"\"\"\n",
    "results = [0]*len(urls)\n",
    "for i, url in enumerate(urls):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    for j, line in enumerate(map(lambda line: line.decode('utf-8').strip('\\n'), data)):\n",
    "        if j == 0:\n",
    "            n, m = map(int, line.split())\n",
    "            edges = []\n",
    "        else:\n",
    "            u, v, cap = map(int, line.split())\n",
    "            edges.append((u - 1, v - 1, cap))\n",
    "    start_time = time.perf_counter()\n",
    "    mf = FordFulkersonMaxFlowV2(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    results[i] = mf\n",
    "    print(f'Finished testcase: {i} in {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs v1: 0.07919800009403843 milliseconds\n",
      "edmonds-karp v1: 0.05266600010145339 milliseconds\n",
      "capacity scaling v1: 0.06254300001273805 milliseconds\n",
      "dinics v1: 0.05668299991157255 milliseconds\n",
      "dfs v2: 0.07072100015648175 milliseconds\n",
      "edmonds-karp v2: 0.05720900003325369 milliseconds\n",
      "capacity scaling v2: 0.06564099999195605 milliseconds\n",
      "dinics v2: 0.06733700001859688 milliseconds\n",
      "============================================================== Test Case 0 Passed ==============================================================\n",
      "dfs v1: 0.04239800000505056 milliseconds\n",
      "edmonds-karp v1: 0.02353600007154455 milliseconds\n",
      "capacity scaling v1: 0.02175999998144107 milliseconds\n",
      "dinics v1: 0.02424000012979377 milliseconds\n",
      "dfs v2: 0.04455100020095415 milliseconds\n",
      "edmonds-karp v2: 0.02800100014610507 milliseconds\n",
      "capacity scaling v2: 0.02737899990279402 milliseconds\n",
      "dinics v2: 0.0314809999508725 milliseconds\n",
      "============================================================== Test Case 1 Passed ==============================================================\n",
      "dfs v1: 0.24929300002440868 milliseconds\n",
      "edmonds-karp v1: 0.14485599990621267 milliseconds\n",
      "capacity scaling v1: 0.23665499998060113 milliseconds\n",
      "dinics v1: 0.15455599987035384 milliseconds\n",
      "dfs v2: 0.21873599985156034 milliseconds\n",
      "edmonds-karp v2: 0.10373899999649439 milliseconds\n",
      "capacity scaling v2: 0.22921300001144118 milliseconds\n",
      "dinics v2: 0.10797699997056043 milliseconds\n",
      "============================================================== Test Case 2 Passed ==============================================================\n",
      "dfs v1: 0.027283999997962383 milliseconds\n",
      "edmonds-karp v1: 0.008783000112089212 milliseconds\n",
      "capacity scaling v1: 0.011793000112447771 milliseconds\n",
      "dinics v1: 0.006487000064225867 milliseconds\n",
      "dfs v2: 0.011698000207616133 milliseconds\n",
      "edmonds-karp v2: 0.006726999799866462 milliseconds\n",
      "capacity scaling v2: 0.012821999916923232 milliseconds\n",
      "dinics v2: 0.005461000000650529 milliseconds\n",
      "============================================================== Test Case 3 Passed ==============================================================\n",
      "dfs v1: 0.7733390000339568 milliseconds\n",
      "edmonds-karp v1: 0.5379169999741862 milliseconds\n",
      "capacity scaling v1: 0.4946430001382396 milliseconds\n",
      "dinics v1: 0.5033739998907549 milliseconds\n",
      "dfs v2: 78.02523000009387 milliseconds\n",
      "edmonds-karp v2: 220.75365199998487 milliseconds\n",
      "capacity scaling v2: 87.85094900008517 milliseconds\n",
      "dinics v2: 5.611936999912359 milliseconds\n",
      "============================================================== Test Case 4 Passed ==============================================================\n",
      "dfs v1: 2.5932030000603845 milliseconds\n",
      "edmonds-karp v1: 3.3409330001177295 milliseconds\n",
      "capacity scaling v1: 3.128105000087089 milliseconds\n",
      "dinics v1: 3.8374540001768764 milliseconds\n",
      "dfs v2: 5.0668000001223845 milliseconds\n",
      "edmonds-karp v2: 5.883675999939442 milliseconds\n",
      "capacity scaling v2: 8.176861000038116 milliseconds\n",
      "dinics v2: 11.56032799985951 milliseconds\n",
      "============================================================== Test Case 5 Passed ==============================================================\n",
      "dfs v1: 11.756351000030918 milliseconds\n",
      "edmonds-karp v1: 6.85582300002352 milliseconds\n",
      "capacity scaling v1: 12.675326999897152 milliseconds\n",
      "dinics v1: 10.555325000041194 milliseconds\n",
      "dfs v2: 28.605795999965267 milliseconds\n",
      "edmonds-karp v2: 14.714843999854565 milliseconds\n",
      "capacity scaling v2: 37.59567499992045 milliseconds\n",
      "dinics v2: 23.360878999937995 milliseconds\n",
      "============================================================== Test Case 6 Passed ==============================================================\n",
      "dfs v1: 0.047797999968679505 milliseconds\n",
      "edmonds-karp v1: 0.023405999854730908 milliseconds\n",
      "capacity scaling v1: 0.01756300002853095 milliseconds\n",
      "dinics v1: 0.023648000023968052 milliseconds\n",
      "dfs v2: 0.028385999939928297 milliseconds\n",
      "edmonds-karp v2: 0.022824999859949457 milliseconds\n",
      "capacity scaling v2: 0.016407999964940245 milliseconds\n",
      "dinics v2: 0.025082999854930677 milliseconds\n",
      "============================================================== Test Case 7 Passed ==============================================================\n",
      "dfs v1: 0.09044199987329193 milliseconds\n",
      "edmonds-karp v1: 0.06105199986450316 milliseconds\n",
      "capacity scaling v1: 0.05084700001134479 milliseconds\n",
      "dinics v1: 0.06017800001245632 milliseconds\n",
      "dfs v2: 0.08075400000961963 milliseconds\n",
      "edmonds-karp v2: 0.06577099998139602 milliseconds\n",
      "capacity scaling v2: 0.05631699991681671 milliseconds\n",
      "dinics v2: 0.07036099987089983 milliseconds\n",
      "============================================================== Test Case 8 Passed ==============================================================\n",
      "dfs v1: 0.154523999981393 milliseconds\n",
      "edmonds-karp v1: 0.050325000074735726 milliseconds\n",
      "capacity scaling v1: 0.11458900007710326 milliseconds\n",
      "dinics v1: 0.08101899993562256 milliseconds\n",
      "dfs v2: 0.09319400010099343 milliseconds\n",
      "edmonds-karp v2: 0.050854999926741584 milliseconds\n",
      "capacity scaling v2: 0.02369799994994537 milliseconds\n",
      "dinics v2: 0.10008699996433279 milliseconds\n",
      "============================================================== Test Case 9 Passed ==============================================================\n",
      "dfs v1: 2.4657880001086596 milliseconds\n",
      "edmonds-karp v1: 2.309577999994872 milliseconds\n",
      "capacity scaling v1: 1.801819000093019 milliseconds\n",
      "dinics v1: 1.5494970000418107 milliseconds\n",
      "dfs v2: 30.567729000040345 milliseconds\n",
      "edmonds-karp v2: 27.750149999974383 milliseconds\n",
      "capacity scaling v2: 22.659824000129447 milliseconds\n",
      "dinics v2: 2.7262869998594397 milliseconds\n",
      "============================================================== Test Case 10 Passed ==============================================================\n",
      "dfs v1: 0.1583800001299096 milliseconds\n",
      "edmonds-karp v1: 0.12927499983561574 milliseconds\n",
      "capacity scaling v1: 0.1046080001287919 milliseconds\n",
      "dinics v1: 0.1632510000035836 milliseconds\n",
      "dfs v2: 0.2121709999300947 milliseconds\n",
      "edmonds-karp v2: 0.3514219999942725 milliseconds\n",
      "capacity scaling v2: 0.22242000000005646 milliseconds\n",
      "dinics v2: 0.32129300006999983 milliseconds\n",
      "============================================================== Test Case 11 Passed ==============================================================\n",
      "dfs v1: 15.406798999947569 milliseconds\n",
      "edmonds-karp v1: 62.76427800003148 milliseconds\n",
      "capacity scaling v1: 5.185758000152418 milliseconds\n",
      "dinics v1: 13.108261999832393 milliseconds\n",
      "dfs v2: 10.430425000095056 milliseconds\n",
      "edmonds-karp v2: 101.31344599994918 milliseconds\n",
      "capacity scaling v2: 8.313853999879939 milliseconds\n",
      "dinics v2: 13.866598000049635 milliseconds\n",
      "============================================================== Test Case 12 Passed ==============================================================\n"
     ]
    }
   ],
   "source": [
    "for i, url in enumerate(urls):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    for j, line in enumerate(map(lambda line: line.decode('utf-8').strip('\\n'), data)):\n",
    "        if j == 0:\n",
    "            n, m = map(int, line.split())\n",
    "            edges = []\n",
    "        else:\n",
    "            u, v, cap = map(int, line.split())\n",
    "            edges.append((u - 1, v - 1, cap))\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dfs1 = FordFulkersonMaxFlowV1(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dfs1 = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_edmonds1 = FordFulkersonMaxFlowV1(n, edges).main_edmonds_karp(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_edmonds_karp1 = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_cp_scaling1 = FordFulkersonMaxFlowV1(n, edges).main_capacity_scaling(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_cp_scaling1 = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dinics1 = FordFulkersonMaxFlowV1(n, edges).main_dinics(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dinics1 = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dfs = FordFulkersonMaxFlowV2(n, edges).main_dfs(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dfs = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_edmonds = FordFulkersonMaxFlowV2(n, edges).main_edmonds_karp(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_edmonds_karp = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_cp_scaling = FordFulkersonMaxFlowV2(n, edges).main_capacity_scaling(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_cp_scaling = duration(start_time, end_time)\n",
    "    start_time = time.perf_counter()\n",
    "    mf_dinics = FordFulkersonMaxFlowV2(n, edges).main_dinics(0, n - 1)\n",
    "    end_time = time.perf_counter()\n",
    "    duration_dinics = duration(start_time, end_time)\n",
    "    assert mf_edmonds1 == results[i], f'Failed on testcase: {i}, output: {mf_edmonds1}, expected: {results[i]} for edmonds-karp algorithm v1'\n",
    "    assert mf_cp_scaling1 == results[i], f'Failed on testcase: {i}, output: {mf_cp_scaling1}, expected: {results[i]} for capacity scaling algorithm v1'\n",
    "    assert mf_dinics1 == results[i], f'Failed on testcase: {i}, output: {mf_dinics1}, expected: {results[i]} for dinics algorithm v1'\n",
    "    assert mf_edmonds == results[i], f'Failed on testcase: {i}, output: {mf_edmonds}, expected: {results[i]} for edmonds-karp algorithm v2'\n",
    "    assert mf_cp_scaling == results[i], f'Failed on testcase: {i}, output: {mf_cp_scaling}, expected: {results[i]} for capacity scaling algorithm v2'\n",
    "    assert mf_dinics == results[i], f'Failed on testcase: {i}, output: {mf_dinics}, expected: {results[i]} for dinics algorithm v2'\n",
    "    print(f'dfs v1: {conv_seconds_milliseconds(duration_dfs1)} milliseconds')\n",
    "    print(f'edmonds-karp v1: {conv_seconds_milliseconds(duration_edmonds_karp1)} milliseconds')\n",
    "    print(f'capacity scaling v1: {conv_seconds_milliseconds(duration_cp_scaling1)} milliseconds')\n",
    "    print(f'dinics v1: {conv_seconds_milliseconds(duration_dinics1)} milliseconds')\n",
    "    print(f'dfs v2: {conv_seconds_milliseconds(duration_dfs)} milliseconds')\n",
    "    print(f'edmonds-karp v2: {conv_seconds_milliseconds(duration_edmonds_karp)} milliseconds')\n",
    "    print(f'capacity scaling v2: {conv_seconds_milliseconds(duration_cp_scaling)} milliseconds')\n",
    "    print(f'dinics v2: {conv_seconds_milliseconds(duration_dinics)} milliseconds')\n",
    "    print(f'============================================================== Test Case {i} Passed ==============================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05a440cbc0a4d5663111a9b3b9ea59349399813ac6e64ad16052767f7ba4c947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
