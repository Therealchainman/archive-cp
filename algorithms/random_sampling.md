# random sampling

## Poisson sampling

Each element of the population may have a different probability of being included in the sample (
$\pi _{i}$). The probability of being included in a sample during the drawing of a single sample is denoted as the first-order inclusion probability of that element (

$p_{i}$). If all first-order inclusion probabilities are equal, Poisson sampling becomes equivalent to Bernoulli sampling, which can therefore be considered to be a special case of Poisson sampling.

## Bernoulli sampling

Bernoulli sampling is therefore a special case of Poisson sampling. In Poisson sampling each element of the population may have a different probability of being included in the sample. In Bernoulli sampling, the probability is equal for all the elements.

Bernoulli sampling is an equal probability, without replacement sampling design. In this method, independent Bernoulli trials on population members determines which members become part of a sample. All members have an equal chance of being part of the sample. The sample sizes in Bernoulli sampling are not fixed, because each member is considered separately for the sample. The method was first introduced by statistician Leo Goodman in 1949, as “binomial sampling”.

The sample size follows a binomial distribution and can take on any value between 0 and N (where N is the size of the sample). If π is the probability of a member being chosen then the expected value (EV) for the sample size is πN. for example, let’s say you had a sample size of 100 and the probability of choosing any one item is 0.1, then the EV would be 0.1 * 100 = 10. However, the sample could theoretically be anywhere from 0 to 100.