# Advent of Code 2023

## Day 1: Trebuchet?!

### Part 2

```py
from collections import *
from functools import *
from itertools import *
import sys
# sys.stdin = open("input.txt", "r")
sys.stdout = open("output.txt", "w")

digits = {"one": "1", "two": "2", "three": "3", "four": "4", "five": "5", "six": "6", "seven": "7", "eight": "8", "nine": "9"}

def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        res = 0
        for s in data:
            left, right = 0, len(s) - 1
            left_dig = right_dig = None
            while left < len(s) and left_dig is None:
                if s[left].isdigit(): 
                    left_dig = s[left]
                    break
                for d, v in digits.items():
                    if d in s[:left + 1]:
                        left_dig = v
                left += 1
            while right >= 0 and right_dig is None:
                if s[right].isdigit(): 
                    right_dig = s[right]
                    break
                for d, v in digits.items():
                    if d in s[right:]:
                        right_dig = v
                right -= 1
            res += int(left_dig + right_dig)
        print(res)

if __name__ == '__main__':
    main()
```

## Day 2: 

### Part 2

```py
def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        res = 0
        for line in data:
            cubes = {"red": 0, "green": 0, "blue": 0}
            # Use regular expression to extract game number and data
            match = re.match(r"Game (\d+): (.+)", line)
            game_number = int(match.group(1))
            game_data_str = match.group(2)
            # Split the game data into individual parts
            parts = game_data_str.split(';')
            # Extract and store data for each part
            flag = True
            for part in parts:
                data = re.findall(r"(\d+) (\w+)", part)
                
                # Extract up to 3 colors (blue, red, green) from each set
                color_values = {'blue': 0, 'red': 0, 'green': 0}
                for count, color in data:
                    if color in color_values:
                        color_values[color] = int(count)
                for color in color_values:
                    cubes[color] = max(cubes[color], color_values[color])
            res += math.prod(cubes.values())
        print(res)             

if __name__ == '__main__':
    main()
```

## Day 3: 

### Part 2

```py
def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        dig = defaultdict(list)
        R, C = len(data), len(data[0])
        for r, line in enumerate(data):
            cur = 0
            start = None
            for c, x in enumerate(line):
                if x.isdigit():
                    if start is None:
                        start = c
                    cur = cur * 10 + int(x)
                else:
                    if start is not None:
                        dig[cur].append((r, start, c - 1))
                    start = None
                    cur = 0
            if start is not None:
                dig[cur].append((r, start, C - 1))
        def check(row, col):
            return data[row][col] == "*"
        gears = defaultdict(list)
        for val, tuples in dig.items():
            for r, c1, c2 in tuples:
                for c in range(max(0, c1 - 1), min(c2 + 2, C)):
                    if check(r, c):
                        gears[(r, c)].append(val)
                    if r > 0 and check(r - 1, c):
                        gears[(r - 1, c)].append(val)
                    if r < R - 1 and check(r + 1, c):
                        gears[(r + 1, c)].append(val) 
        res = sum(math.prod(values) for values in gears.values() if len(values) == 2)
        print(res)             

if __name__ == '__main__':
    main()
```

## Day 4: 

### Part 1

```py
def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        res = 0
        for i, line in enumerate(data):
            _, after_part = line.split(":")
            before, after = after_part.split("|")
            before_numbers = set(map(int, before.split()))
            after_numbers = list(map(int, after.split()))
            cnt = sum(1 for num in after_numbers if num in before_numbers)
            if cnt == 0: continue
            res += pow(2, cnt - 1)
        print(res)             

if __name__ == '__main__':
    main()
```

## Day 4:

### Part 2

```py
def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        cards = [1] * len(data)         
        for card_index, line in enumerate(data):
            _, after_part = line.split(":")
            before, after = after_part.split("|")
            before_numbers = set(map(int, before.split()))
            after_numbers = list(map(int, after.split()))
            cnt = sum(1 for num in after_numbers if num in before_numbers)
            for i in range(card_index + 1, card_index + cnt + 1):
                cards[i] += cards[card_index]
        print(sum(cards))             

if __name__ == '__main__':
    main()
```

## Day 5: 

### Part 1

```py
def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        _, seeds = data[0].split(":")
        seeds = list(map(int, seeds.split()))
        ptr = 0
        maps = ["seed-to-soil", "soil-to-fertilizer", "fertilizer-to-water", "water-to-light", "light-to-temperature", "temperature-to-humidity", "humidity-to-location"]
        mappers = [[] for _ in range(len(maps))]
        for line in data[2:]:
            if line == "": 
                ptr += 1
                continue
            if maps[ptr] in line: continue
            dest, source, len_ = map(int, line.split())
            if maps[ptr] == "seed-to-soil":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "soil-to-fertilizer":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "fertilizer-to-water":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "light-to-temperature":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "temperature-to-humidity":
                mappers[ptr].append((source, dest, len_))
            else:
                mappers[ptr].append((source, dest, len_))
        for i in range(len(mappers)):
            mappers[i].sort()
        res = math.inf
        for i in range(0, len(seeds), 2):
            start = seeds[i]
            end = seeds[i] + seeds[i + 1]
            for seed in range(start, end):
                val = seed
                for i in range(len(mappers)):
                    j = bisect.bisect_right(mappers[i], (val, math.inf, math.inf)) - 1
                    if j == -1 or val > mappers[i][j][0] + mappers[i][j][2]: continue
                    else: val = mappers[i][j][1] + (val - mappers[i][j][0])
                res = min(res, val)
        print(res)      

if __name__ == '__main__':
    main()
```

## Day 5: 

### Part 2:  ranges, intersection of ranges, split ranges

```py
def apply_range(ranges, ma):
    ans = []
    for src, dst, len_ in ma:
        src_end = src + len_ # [src, src_end)
        new_ranges = []
        while ranges:
            s, e = ranges.pop()
            left = (s, min(src, e))
            mid = (max(s, src), min(e, src_end))
            right = (max(s, src_end), e)
            if left[1] > left[0]:
                new_ranges.append(left)
            if mid[1] > mid[0]:
                ans.append((dst + mid[0] - src, dst + mid[1] - src))
            if right[1] > right[0]:
                new_ranges.append(right)
        ranges = new_ranges
    ans.extend(ranges)
    return ans
def main():
    with open('input.txt', 'r') as f:
        data = f.read().splitlines()
        _, seeds = data[0].split(":")
        seeds = list(map(int, seeds.split()))
        ptr = 0
        maps = ["seed-to-soil", "soil-to-fertilizer", "fertilizer-to-water", "water-to-light", "light-to-temperature", "temperature-to-humidity", "humidity-to-location"]
        mappers = [[] for _ in range(len(maps))]
        for line in data[2:]:
            if line == "": 
                ptr += 1
                continue
            if maps[ptr] in line: continue
            dest, source, len_ = map(int, line.split())
            if maps[ptr] == "seed-to-soil":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "soil-to-fertilizer":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "fertilizer-to-water":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "light-to-temperature":
                mappers[ptr].append((source, dest, len_))
            elif maps[ptr] == "temperature-to-humidity":
                mappers[ptr].append((source, dest, len_))
            else:
                mappers[ptr].append((source, dest, len_))
        res = math.inf
        for i in range(0, len(seeds), 2):
            print("i", i)
            ranges = [(seeds[i], seeds[i] + seeds[i + 1])] # [s, e), length = e - s
            for ma in mappers:
                ranges = apply_range(ranges, ma)
                print("ranges: ", len(ranges))
            for s, _ in ranges:
                res = min(res, s)
        print(res)      

if __name__ == '__main__':
    main()
```

## Day 6: 

### Solution 1:  binary search, but you need to find the peak, parabola

```py
def solve(distances, times):
    res = 1
    for t, d in zip(times, distances):
        peak = t // 2
        i = bisect.bisect_left(range(peak), d, key = lambda x: x * (t - x))
        j = bisect.bisect_right(range(peak, t + 1), False, key = lambda x: x * (t - x) <= d) + peak
        res *= (j - i)
    return res
def main():
    with open("big.txt", "r") as f:
        data = f.read().splitlines()
        _, times = data[0].split((":"))
        times = list(map(int, times.split()))
        _, distances = data[1].split(":")
        distances = list(map(int, distances.split()))
        print("part 1:", solve(distances, times))
        distances = [int("".join(map(str, distances)))]
        times = [int("".join(map(str, times)))]
        print("part 2:", solve(distances, times))
main()
```

## Day 7: 

### Solution 1: custom sorting

```py
card_values = {'A': 14, 'K': 13, 'Q': 12, 'J': 11, 'T': 10, '9': 9, '8': 8, '7': 7, '6': 6, '5': 5, '4': 4, '3': 3, '2': 2}
def hand_value(hand):
    return tuple(card_values[hand[i]] for i in range(5))
def hand_rank(hand):
    card_counts = Counter()
    for card in hand:
        card_counts[card] += 1
    counts = sorted(card_counts.values(), reverse=True)
    if counts == [5]:
        # Five of a kind
        return (7, hand_value(hand))
    elif counts == [4, 1]:
        # Four of a kind
        return (6, hand_value(hand))
    elif counts == [3, 2]:
        # Full house
        return (5, hand_value(hand))
    elif counts == [3, 1, 1]:
        # Three of a kind
        return (4, hand_value(hand))
    elif counts == [2, 2, 1]:
        # Two pair
        return (3, hand_value(hand))
    elif counts == [2, 1, 1, 1]:
        # One pair
        return (2, hand_value(hand))
    else:
        # High card
        return (0, hand_value(hand))
def modify_hand(hand):
    # generate every possible hand 
    hand = list(hand)
    cand_hands = [hand]
    for i in range(5):
        if hand[i] == "J":
            next_cands = []
            for card, cand in product(card_values.keys(), cand_hands):
                new_cand = cand[:]
                new_cand[i] = card
                next_cands.append(new_cand)
            cand_hands = next_cands
    # choose the best hand
    return max(cand_hands, key = lambda x: hand_rank(x))
def solve(hands, values):
    hands.sort(key = lambda x: hand_rank(x[0]), reverse = True)
    return sum(rank * values[i] for rank, (hand, i) in enumerate(reversed(hands), start = 1))
def main():
    with open('big.txt', 'r') as f:
        data = f.read().splitlines()
        n = len(data)
        hands = []
        values = [None] * n
        for i, line in enumerate(data):
            hand, val = line.split()
            values[i] = int(val)
            hands.append((hand, i))
        part_1 = solve(hands, values)
        card_values["J"] = 1
        for i, (hand, idx) in enumerate(hands):
            hands[i] = (modify_hand(hand), idx)
        part_2 = solve(hands, values)
        print("part 1:", part_1)
        print("part 2:", part_2)
main()
```

## Day 8: 

### Part 2: least common multiple LCM, number of steps between each Z for each node

```py
D = compile("{} = ({}, {})")
LIM = 1_000_000
with open('input.txt', 'r') as f:
    data = f.read().splitlines()
    instructions = data[0]
    n = len(instructions)
    dir = {}
    for line in data[2:]:
        f, L, R = D.parse(line).fixed
        dir[f] = (L, R)
    nodes = list(filter(lambda x: x[-1] == "A", dir.keys()))
    print(nodes)
    deltas = [0] * len(nodes)
    last = [0] * len(nodes)
    for i in range(LIM):
        for j in range(len(nodes)):
            if instructions[i % n] == "L":
                val = dir[nodes[j]][0]
                nodes[j] = val
                if val[-1] == "Z":
                    deltas[j]= i + 1 - last[j]
                    last[j] = i + 1
            else:
                val = dir[nodes[j]][1]
                nodes[j] = val
                if val[-1] == "Z":
                    deltas[j] = i + 1 - last[j]
                    last[j] = i + 1
    print(deltas)
    print(math.lcm(*deltas))
```

## Day 9: 

### Part 2:  math, arithmetic series

```py
with open('input.txt', 'r') as f:
    data = f.read().splitlines()
    grid = [list(map(int, line.split())) for line in data]
    res = 0
    for line in map(lambda x: x[::-1], grid):
        last = [line[-1]]
        while True:
            nxt_line = [0] * (len(line) - 1)
            for i in range(1, len(line)):
                nxt_line[i - 1] = line[i] - line[i - 1]
            line = nxt_line
            last.append(line[-1])
            if all(x == 0 for x in line): break
        res += sum(last)
    print(res)
```

## Day 10: 

### Solution 1: graph, cycle graph, simple cycle, point in polygon, ray casting, rectilinear polygon

```py
connections = {
    (1, 0): "LJ|",
    (-1, 0): "F7|",
    (0, 1): "J7-",
    (0, -1): "FL-"
}
movements = {
        '|': "UD",
        '-': "LR",
        'L': "UR",
        'J': "UL",
        '7': "DL",
        'F': "DR",
        '.': "",
    }
directions = {
    "U": (-1, 0),
    "D": (1, 0),
    "R": (0, 1),
    "L": (0, -1),
}
def find_start(grid):
    R, C = len(grid), len(grid[0])
    for r, c in product(range(R), range(C)):
        if grid[r][c] == "S": return r, c
    return 0, 0
def find_loop(sr, sc, grid, vis):
    res = 1
    r, c = sr, sc
    dr, dc = directions[movements[grid[sr][sc]][0]]
    pr, pc = sr, sc
    r += dr
    c += dc
    if grid[r][c] not in connections[(dr, dc)]: return -1
    found = True
    while found:
        res += 1
        vis[r][c] = 1
        found = False
        for heading in movements[grid[r][c]]:
            dr, dc = directions[heading]
            nr, nc = r + dr, c + dc
            if grid[nr][nc] not in connections[(dr, dc)]: return -1
            if (nr, nc) == (pr, pc): continue
            if (nr, nc) == (sr, sc): return res
            pr, pc = r, c
            r, c = nr, nc
            found = True
            break
    return -1
def point_in_polygon(grid, vis):
    R, C = len(grid), len(grid[0])
    inside = 0
    for r in range(R):
        up = down = 0
        for c in range(C):
            if not vis[r][c] and up and down:
                inside += 1
            if vis[r][c]:
                for heading in movements[grid[r][c]]:
                    if heading == "U": up ^= 1
                    if heading == "D": down ^= 1
    return inside
def main():
    with open("big.txt", "r") as f:
        data = f.read().splitlines()
        grid = [list(line) for line in data]
        R, C = len(grid), len(grid[0])
        sr, sc = find_start(grid)
        for pipe in "|-LJ7F":
            vis = [[0] * C for _ in range(R)]
            vis[sr][sc] = 1
            grid[sr][sc] = pipe # try with this pipe
            num_nodes = find_loop(sr, sc, grid, vis)
            if num_nodes > 0:
                part_1 = num_nodes // 2
                part_2 = point_in_polygon(grid, vis)
                return part_1, part_2
p1, p2 = main()
print("part 1:", p1)
print("part 2:", p2)
```

### Solution 2:  simple cycle, cycle graph, shoelace formula, pick's theorem, lattice polygon

```py
connections = {
    (1, 0): "LJ|",
    (-1, 0): "F7|",
    (0, 1): "J7-",
    (0, -1): "FL-"
}
movements = {
        '|': "UD",
        '-': "LR",
        'L': "UR",
        'J': "UL",
        '7': "DL",
        'F': "DR",
        '.': "",
    }
directions = {
    "U": (-1, 0),
    "D": (1, 0),
    "R": (0, 1),
    "L": (0, -1),
}
def find_start(grid):
    R, C = len(grid), len(grid[0])
    for r, c in product(range(R), range(C)):
        if grid[r][c] == "S": return r, c
    return 0, 0
def find_loop(sr, sc, grid, vertices):
    res = 1
    r, c = sr, sc
    dr, dc = directions[movements[grid[sr][sc]][0]]
    pr, pc = sr, sc
    r += dr
    c += dc
    if grid[r][c] not in connections[(dr, dc)]: return -1
    found = True
    while found:
        res += 1
        vertices.append((r, c))
        found = False
        for heading in movements[grid[r][c]]:
            dr, dc = directions[heading]
            nr, nc = r + dr, c + dc
            if grid[nr][nc] not in connections[(dr, dc)]: return -1
            if (nr, nc) == (pr, pc): continue
            if (nr, nc) == (sr, sc): return res
            pr, pc = r, c
            r, c = nr, nc
            found = True
            break
    return -1
def shoelace(vertices):
    double_area = 0
    n = len(vertices)
    for i in range(n):
        x1, y1 = vertices[i]
        x2, y2 = vertices[(i + 1) % n]
        double_area += x1 * y2 - x2 * y1
    double_area = abs(double_area)
    return double_area // 2
# find number of interior points
def picks_theorem(A, b):
    return A - b // 2 + 1
def main():
    with open("big.txt", "r") as f:
        data = f.read().splitlines()
        grid = [list(line) for line in data]
        R, C = len(grid), len(grid[0])
        sr, sc = find_start(grid)
        for pipe in "|-LJ7F":
            vertices = [(sr, sc)]
            grid[sr][sc] = pipe # try with this pipe
            num_nodes = find_loop(sr, sc, grid, vertices)
            if num_nodes > 0:
                part_1 = num_nodes // 2
                part_2 = picks_theorem(shoelace(vertices), num_nodes)
                return part_1, part_2
p1, p2 = main()
print("part 1:", p1)
print("part 2:", p2)
```

### Solution 3:  matplotlib Path object, creates a path from a set of integer coordinates, and then you can determine how many points are inside that enclosed path

```py
connections = {
    (1, 0): "LJ|",
    (-1, 0): "F7|",
    (0, 1): "J7-",
    (0, -1): "FL-"
}
movements = {
        '|': "UD",
        '-': "LR",
        'L': "UR",
        'J': "UL",
        '7': "DL",
        'F': "DR",
        '.': "",
    }
directions = {
    "U": (-1, 0),
    "D": (1, 0),
    "R": (0, 1),
    "L": (0, -1),
}
def find_start(grid):
    R, C = len(grid), len(grid[0])
    for r, c in product(range(R), range(C)):
        if grid[r][c] == "S": return r, c
    return 0, 0
def find_loop(sr, sc, grid, vertices):
    res = 1
    r, c = sr, sc
    dr, dc = directions[movements[grid[sr][sc]][0]]
    pr, pc = sr, sc
    r += dr
    c += dc
    if grid[r][c] not in connections[(dr, dc)]: return -1
    found = True
    while found:
        res += 1
        vertices.append((r, c))
        found = False
        for heading in movements[grid[r][c]]:
            dr, dc = directions[heading]
            nr, nc = r + dr, c + dc
            if grid[nr][nc] not in connections[(dr, dc)]: return -1
            if (nr, nc) == (pr, pc): continue
            if (nr, nc) == (sr, sc): return res
            pr, pc = r, c
            r, c = nr, nc
            found = True
            break
    return -1
def path():
    res = 0
    p = Path(vertices)
    v_set = set(vertices)
    for r, c in product(range(R), range(C)):
        if (r, c) in v_set: continue
        if p.contains_point((r, c)): res += 1
    return res
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    grid = [list(line) for line in data]
    R, C = len(grid), len(grid[0])
    sr, sc = find_start(grid)
    for pipe in "|-LJ7F":
        vertices = [(sr, sc)]
        grid[sr][sc] = pipe # try with this pipe
        num_nodes = find_loop(sr, sc, grid, vertices)
        if num_nodes > 0:
            part_1 = num_nodes // 2
            part_2 = path()
            print("part 1:", part_1)
            print("part 2:", part_2)
            break
```

## Day 11: 

### Part 2, grid, prefix sum, manhattan distance

```py
def solve(m):
    with open("input.txt", "r") as f:
        data = f.read().splitlines()
        R, C = len(data), len(data[0])
        grid = [list(line) for line in data]
        rows = [0] * R
        cols = [0] * C
        prows = [0] * (R + 1)
        pcols = [0] * (C + 1)
        nodes = []
        # mark non empty rows
        for r, c in product(range(R), range(C)):
            if grid[r][c] == "#":
                rows[r] = cols[c] = 1
                nodes.append((r, c))
        # create prefix sum, including the size for the empty rows and columns
        for r in range(R):
            prows[r + 1] = prows[r] + (m - 1) * (rows[r] == 0)
        for c in range(C):
            pcols[c + 1] = pcols[c] + (m - 1) * (cols[c] == 0)
        def calc(x1, x2, psum):
            xmax, xmin = max(x1, x2), min(x1, x2)
            return xmax - xmin + psum[xmax] - psum[xmin]
        res = 0
        # manhattan distance between each pair of galaxy and
        # for rows and colums independently do the following
        # for example with rows it is [rmin, rmax), which will include all the emtpy rows and the count of empty space between
        for i in range(len(nodes)):
            for j in range(i):
                r1, c1 = nodes[i]
                r2, c2 = nodes[j]
                dist_r = calc(r1, r2, prows)
                dist_c = calc(c1, c2, pcols)
                res += dist_r + dist_c
        return res
assert solve(1_000_000) == 791134099634
```

## Day 12: 

### Solution 1:  dynamic programming with bags

```py
def solve(elements, groups):
    # state = (current group size, current group index, last character)
    bags = Counter()
    if elements[0] == "?" or elements[0] == "#":
        bags[(1, 0)] += 1
    if elements[0] == "?" or elements[0] == ".":
        bags[(0, 0)] += 1
    n = len(elements)
    m = len(groups)
    for i in range(1, n):
        new_bags = Counter()
        for (cur, j), cnt in bags.items():
            if elements[i] == ".":
                if cur == 0:
                    new_bags[(0, j)] += cnt
                elif cur == groups[j]:
                    new_bags[(0, j + 1)] += cnt
            elif elements[i] == "#":
                if j < m and cur < groups[j]:
                    new_bags[(cur + 1, j)] += cnt
            else:
                if cur == 0:
                    new_bags[(0, j)] += cnt
                    if j < m:
                        new_bags[(1, j)] += cnt
                elif cur == groups[j]:
                    new_bags[(0, j + 1)] += cnt
                elif cur > 0:
                    new_bags[(cur + 1, j)] += cnt
        bags = new_bags
    return sum(cnt for (_, j), cnt in bags.items() if j == m)
def parts(sz):
    with open("big.txt", "r") as f:
        data = f.read().splitlines()
        res = 0
        for line in data:
            first, second = line.split()
            start = list(map(int, second.split(",")))
            elements = "?".join([first for _ in range(sz)]) + "."
            groups = []
            for _ in range(sz):
                groups.extend(start)
            res += solve(elements, groups)
        return res
print("part 1:", parts(1))
print("part 2:", parts(5))
```

## Day 13: 

### Solution 1: grid, reflection, all and any, list and string slicing

```py
def main():
    with open('big.txt', 'r') as f:
        data = f.read().splitlines()
        partitions = [-1] + [i for i, line in enumerate(data) if not line] + [len(data)]
        grids = [data[partitions[i - 1] + 1 : partitions[i]] for i in range(1, len(partitions))]
        def check_horizontal(r):
            return all(r1 == r2 for r1, r2 in zip(grid[r:], reversed(grid[:r])))
        def check_vertical(c):
            for row in grid:
                if any(c1 != c2 for c1, c2 in zip(row[c:], reversed(row[:c]))): return False
            return True
        def find_horizontal():
            for r in range(1, R):
                if check_horizontal(r): return r 
            return 0
        def find_vertical():
            for c in range(1, C):
                if check_vertical(c): return c 
            return 0
        def find_reflection(cur_r, cur_c):
            for r, c in product(range(R), range(C)):
                tmp = grid[r][c]
                grid[r][c] = "#" if tmp == "." else "."
                for i in range(1, R):
                    if check_horizontal(i) and i != cur_r: return i, 0
                for j in range(1, C):
                    if check_vertical(j) and j != cur_c: return 0, j
                grid[r][c] = tmp
            return 0, 0
        row_count = col_count = rcount = ccount = 0
        for grid in map(lambda gr: [list(line) for line in gr], grids):
            R, C = len(grid), len(grid[0])
            cur_r, cur_c = find_horizontal(), find_vertical()
            rcount += cur_r
            ccount += cur_c
            new_r, new_c = find_reflection(cur_r, cur_c)
            row_count += new_r
            col_count += new_c
        print("part 1:", ccount + 100 * rcount)
        print("part 2:", col_count + 100 * row_count)
main()
```

## Day 14: 

### Solution 1:  complex numbers, moving all objects to the top, bottom, left, righte

```py
def part1():
    with open('big.txt', 'r') as f:
        data = f.read().splitlines()
        grid = [list(line) for line in data]
        R, C = len(grid), len(grid[0])
        rocks = set()
        objects = []
        for r, c in product(range(R), range(C)):
            if grid[r][c] == "#":
                rocks.add(c + r * 1j)
            elif grid[r][c] == "O":
                objects.append(c + r * 1j)
        res = 0
        vis = set()
        def good(z):
            return z not in rocks and z not in vis
        def north(objects):
            vis.clear()
            new_objects = []
            for obj in sorted(objects, key = lambda z: vertical(z)):
                z = obj
                while z.imag > 0:
                    if good(z - 1j):
                        z -= 1j
                    else:
                        break
                vis.add(z)
                new_objects.append(z)
            return new_objects
        objects = north(objects)
        return int(sum(R - z.imag for z in objects))
def part2():
    # north, west, south, east
    vertical = lambda z: (z.imag, z.real)
    horizontal = lambda z: (z.real, z.imag)
    cycles = 1_000_000_000
    with open('big.txt', 'r') as f:
        data = f.read().splitlines()
        grid = [list(line) for line in data]
        R, C = len(grid), len(grid[0])
        rocks = set()
        objects = []
        for r, c in product(range(R), range(C)):
            if grid[r][c] == "#":
                rocks.add(c + r * 1j)
            elif grid[r][c] == "O":
                objects.append(c + r * 1j)
        cnt = 0
        objects.sort(key = lambda z: vertical(z))
        first, second = {}, {}
        vis = set()
        def good(z):
            return z not in rocks and z not in vis
        def north(objects):
            vis.clear()
            new_objects = []
            for obj in sorted(objects, key = lambda z: vertical(z)):
                z = obj
                while z.imag > 0:
                    if good(z - 1j):
                        z -= 1j
                    else:
                        break
                vis.add(z)
                new_objects.append(z)
            return new_objects
        def west(objects):
            vis.clear()
            new_objects = []
            for obj in sorted(objects, key = lambda z: horizontal(z)):
                z = obj
                while z.real > 0:
                    if good(z - 1):
                        z -= 1
                    else:
                        break
                vis.add(z)
                new_objects.append(z)
            return new_objects
        def south(objects):
            vis.clear()
            new_objects = []
            for obj in sorted(objects, key = lambda z: vertical(z), reverse = True):
                z = obj
                while z.imag < R - 1:
                    if good(z + 1j):
                        z += 1j
                    else:
                        break
                vis.add(z)
                new_objects.append(z)
            return new_objects
        def east(objects):
            vis.clear()
            new_objects = []
            for obj in sorted(objects, key = lambda z: horizontal(z), reverse = True):
                z = obj
                while z.real < C - 1:
                    if good(z + 1):
                        z += 1
                    else:
                        break
                vis.add(z)
                new_objects.append(z)
            return new_objects
        while True:
            objects = north(objects)
            objects = west(objects)
            objects = south(objects)
            objects = east(objects)
            objects.sort(key = lambda z: vertical(z))
            cnt += 1
            hash = tuple(objects)
            if hash in first and hash in second: break
            if hash in first:
                second[hash] = cnt
            else:
                first[hash] = cnt
        ran = min(second.values())
        remaining_cycles = cycles - ran
        rem = remaining_cycles % len(second)
        for k in second.keys():
            second[k] -= ran
        for key, val in second.items():
            if val == rem: return int(sum(R - z.imag for z in key))
print("part 1", part1())
print("part 2", part2())
```

## Day 15: 

### Solution 1:  deque, hashmap, object oriented, hashing

```py
def part1(data):
    mod = 256
    res = 0
    for s in data:
        h = 0
        for ch in s:
            h += ord(ch)
            h *= 17
            h %= mod
        res += h
    return res
assign = compile("{}={:d}")
negate = compile("{}-")
class Box:
    def __init__(self, index):
        self.queue = deque()
        self.focal_lengths = {}
        self.index = index
    def add(self, ss, focal):
        if ss not in self.focal_lengths:
            self.queue.append(ss)
        self.focal_lengths[ss] = focal
    def remove(self, ss):
        if ss in self.focal_lengths:
            del self.focal_lengths[ss]
            self.queue.remove(ss)
    def evaluate(self):
        ans = j = 0
        for j in range(len(self.queue)):
            ans += (self.index + 1) * (j + 1) * self.focal_lengths[self.queue[j]]
        return ans
    def __repr__(self):
        return f"queue: {self.queue}, focal_lengths: {self.focal_lengths}"
def part2(data):
    mod = 256
    boxes = [Box(i) for i in range(256)]
    for line in data:
        focal = None
        if assign.parse(line):
            ss, focal = assign.parse(line).fixed
        else:
            ss = negate.parse(line).fixed[0]
        box_index = 0
        for ch in ss:
            box_index += ord(ch)
            box_index *= 17
            box_index %= mod
        if focal:
            boxes[box_index].add(ss, focal)
        else:
            boxes[box_index].remove(ss)
    return sum(box.evaluate() for box in boxes)
with open('big.txt', 'r') as f:
    data = f.read().splitlines()[0].split(",")
    print("part 1:", part1(data))
    print("part 2:", part2(data))
```

## Day 16: 

### Solution 1: 

```py
directions = {
    "E": (0, 1),
    "W": (0, -1),
    "N": (-1, 0),
    "S": (1, 0)
}

with open("big.txt", "r") as f:
    data = f.read().splitlines()
    grid = [list(line) for line in data]
    R, C = len(grid), len(grid[0])
    columns = {
        0: "E",
        C - 1: "W"
    }
    rows = {
        0: "S",
        R - 1: "N"
    }
    def get(r, c, d):
        res = []
        ch = grid[r][c]
        if ch == "|" and d in "EW":
            res.append("N")
            res.append("S")
        elif ch == "-" and d in "NS":
            res.append("E")
            res.append("W")
        elif ch == "/":
            if d == "E":
                res.append("N")
            elif d == "N":
                res.append("E")
            elif d == "W":
                res.append("S")
            elif d == "S":
                res.append("W")
        elif ch == "\\":
            if d == "E":
                res.append("S")
            elif d == "N":
                res.append("W")
            elif d == "W":
                res.append("N")
            elif d == "S":
                res.append("E")
        else:
            res.append(d)
        return res
    def bfs(q, memo):
        seen = set()
        in_bounds = lambda r, c: 0 <= r < R and 0 <= c < C
        while q:
            r, c, d = q.popleft()
            seen.add((r, c))
            dr, dc = directions[d]
            r += dr
            c += dc
            if not in_bounds(r, c): continue
            dirs = get(r, c, d)
            for d in dirs:
                if (r, c, d) not in memo:
                    memo.add((r, c, d))
                    q.append((r, c, d))
        return len(seen)
    res = 0
    starts = [(0, c) for c in range(C)] + [(R - 1, c) for c in range(C)] + [(r, 0) for r in range(1, R - 1)] + [(r, C - 1) for r in range(1, R - 1)]
    for r, c in starts:
        if r in rows:
            q = deque()
            memo = set()
            dirs = get(r, c, rows[r])
            for d in dirs:
                q.append((r, c, d))
                memo.add((r, c, d))
            current = bfs(q, memo)
            res = max(res, current)
        if c in columns:
            q = deque()
            memo = set()
            dirs = get(r, c, columns[c])
            for d in dirs:
                q.append((r, c, d))
                memo.add((r, c, d))
            current = bfs(q, memo)
            if (r, c) == (0, 0):
                print("part 1:", current)
            res = max(res, current)
    print("part 2:", res)
```

## Day 17: 

### Solution 1: 

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    grid = [list(map(int, line)) for line in data]
    R, C = len(grid), len(grid[0])
    in_bounds = lambda r, c: 0 <= r < R and 0 <= c < C
    memo = set()
    heap = [(0, 0, 0, 0, 0, 0)]
    while heap:
        cost, r, c, dr, dc, steps = heapq.heappop(heap)
        if (r, c, dr, dc, steps) in memo: continue
        memo.add((r, c, dr, dc, steps))
        if (r, c) == (R - 1, C - 1): print(cost); break
        if steps < 3:
            nr, nc = r + dr, c + dc
            if in_bounds(nr, nc):
                heapq.heappush(heap, (cost + grid[nr][nc], nr, nc, dr, dc, steps + 1))
        for ndr, ndc in [(0, 1), (1, 0), (-1, 0), (0, -1)]:
            if (ndr, ndc) == (dr, dc) or (ndr, ndc) == (-dr, -dc): continue
            nr, nc = r + ndr, c + ndc
            if in_bounds(nr, nc):
                heapq.heappush(heap, (cost + grid[nr][nc], nr, nc, ndr, ndc, 1))
```

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    grid = [list(map(int, line)) for line in data]
    R, C = len(grid), len(grid[0])
    in_bounds = lambda r, c: 0 <= r < R and 0 <= c < C
    memo = set()
    heap = [(0, 0, 0, 0, 0, 10)]
    while heap:
        cost, r, c, dr, dc, steps = heapq.heappop(heap)
        if (r, c, dr, dc, steps) in memo: continue
        memo.add((r, c, dr, dc, steps))
        if steps >= 4 and (r, c) == (R - 1, C - 1): print(cost); break
        if steps < 10: # cannot go straight after 10 steps
            nr, nc = r + dr, c + dc
            if in_bounds(nr, nc):
                heapq.heappush(heap, (cost + grid[nr][nc], nr, nc, dr, dc, steps + 1))
        if steps >= 4: # minimum of 4 steps before turns
            for ndr, ndc in [(0, 1), (1, 0), (-1, 0), (0, -1)]:
                if (ndr, ndc) == (dr, dc) or (ndr, ndc) == (-dr, -dc): continue
                nr, nc = r + ndr, c + ndc
                if in_bounds(nr, nc):
                    heapq.heappush(heap, (cost + grid[nr][nc], nr, nc, ndr, ndc, 1))
```

## Day 18: 

### Solution 1:  shoelace formula, picks theorem, finding interior and boundary points, hexadecimal

```py
wall = compile("{} {:d} {}")
directions = {
    "L": (0, -1),
    "R": (0, 1),
    "U": (-1, 0),
    "D": (1, 0)
}
def shoelace(vertices):
    double_area = 0
    n = len(vertices)
    for i in range(n):
        x1, y1 = vertices[i]
        x2, y2 = vertices[(i + 1) % n]
        double_area += x1 * y2 - x2 * y1
    double_area = abs(double_area)
    return double_area // 2
# find number of interior points
def picks_theorem(A, b):
    return A - b // 2 + 1
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    r = c = 0
    grid = set([(r, c)])
    polygon = [(r, c)]
    b = 0
    for line in data:
        d, dist, _ = wall.parse(line).fixed
        b += dist
        dr, dc = directions[d]
        r += dr * dist
        c += dc * dist
        grid.add((r, c))
        polygon.append((r, c))
    polygon.pop()
    # area of polygon
    A = shoelace(polygon)
    # number interior points
    I = picks_theorem(A, b)
    print("part 1:", I + b)
```

```py
wall = compile("{} {:d} ({})")
directions = {
    "L": (0, -1),
    "R": (0, 1),
    "U": (-1, 0),
    "D": (1, 0)
}
dirs = "RDLU"
def shoelace(vertices):
    double_area = 0
    n = len(vertices)
    for i in range(n):
        x1, y1 = vertices[i]
        x2, y2 = vertices[(i + 1) % n]
        double_area += x1 * y2 - x2 * y1
    double_area = abs(double_area)
    return double_area // 2
# find number of interior points
def picks_theorem(A, b):
    return A - b // 2 + 1
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    r = c = 0
    grid = set([(r, c)])
    polygon = [(r, c)]
    b = 0
    for line in data:
        _, _, key = wall.parse(line).fixed
        hex = key[1:6]
        dist = int(hex, 16)
        d = dirs[int(key[-1])]
        b += dist
        dr, dc = directions[d]
        r += dr * dist
        c += dc * dist
        grid.add((r, c))
        polygon.append((r, c))
    polygon.pop()
    # area of polygon
    A = shoelace(polygon)
    # number interior points
    I = picks_theorem(A, b)
    print("part 2:", I + b)
```

## Day 19: 

### Solution 1:  directed graph, dependency graph, control structure, conditionals, ranges, regex

```py
part = compile("{{x={:d},m={:d},a={:d},s={:d}}}")
less = compile("{}<{:d}")
greater = compile("{}>{:d}")
name_pat = "^[a-z]*"
cond_pat = "{.*}"
class Workflow:
    def __init__(self, s):
        cands = s.split(",")
        self.conditions = []
        self.responses = []
        self.default = cands.pop()
        for cand in cands:
            cond, resp = cand.split(":")
            self.conditions.append(cond)
            self.responses.append(resp)
    def evaluate(self, x, m, a, s):
        for cond, resp in zip(self.conditions, self.responses):
            if eval(cond): return resp
        return self.default
    def __repr__(self):
        return f"conditions = {self.conditions}, response = {self.responses}, default = {self.default}"
def get_ways(ranges):
    return math.prod(e - s for s, e in ranges.values())
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    parts = False
    workflows = {}
    p1 = 0
    for line in data:
        if len(line) == 0:
            parts = True
        elif parts:
            x, m, a, s = part.parse(line).fixed
            cur = "in"
            while cur not in "AR":
                cur = workflows[cur].evaluate(x, m, a, s)
            if cur == "A":
                p1 += sum([x, m, a, s])
        else:
            name = re.findall(name_pat, line)[0]
            work = re.findall(cond_pat, line)[0]
            workflows[name] = Workflow(work[1:-1])
    p2 = 0
    init_range = (1, 4001)
    stack = [("in", {"x": init_range, "m": init_range, "a": init_range, "s": init_range})]
    while stack:
        name, ranges = stack.pop()
        workflow = workflows[name]
        for cond, resp in zip(workflow.conditions, workflow.responses):
            oranges = ranges.copy() # other range
            nranges = ranges.copy() # get's split from current range
            if less.parse(cond):
                p, v = less.parse(cond).fixed
                for k, (s, e) in ranges.items():
                    if k == p: # [s, v), [v, e)
                        left_seg = (s, min(v, e))
                        right_seg = (max(s, v), e)
                        nranges[k] = left_seg
                        oranges[k] = right_seg
            elif greater.parse(cond):
                p, v = greater.parse(cond).fixed
                v += 1 # convert to greater than or equal
                for k, (s, e) in ranges.items():
                    if k == p: # [s, v), [v, e)
                        left_seg = (s, min(e, v))
                        right_seg = (max(s, v), e)
                        nranges[k] = right_seg
                        oranges[k] = left_seg
            if resp == "A": p2 += get_ways(nranges)
            elif resp != "R": stack.append((resp, nranges))
            ranges = oranges
        if workflow.default not in "AR": stack.append((workflow.default, ranges))
        if workflow.default == "A": p2 += get_ways(ranges)
    print("part 1:", p1)
    print("part 2:", p2)
```

## Day 20: 

### Solution 1: 

```py
flip_flop = parse.compile("%{} -> {}")
conjunction = parse.compile("&{} -> {}")
broad = parse.compile("broadcaster -> {}")
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    start = "broadcaster"
    flop = "flip_flop"
    con = "conjunction"
    adj = defaultdict(list)
    module_type = {}
    seen = set()
    inputs = defaultdict(list)
    for line in data:
        if broad.parse(line):
            modules = broad.parse(line).fixed[0]
            for module in modules.split(", "):
                adj[start].append(module)
        elif flip_flop.parse(line):
            name, modules = flip_flop.parse(line).fixed
            module_type[name] = flop
            for module in modules.split(", "):
                adj[name].append(module)
        else:
            name, modules = conjunction.parse(line).fixed
            module_type[name] = con
            for module in modules.split(", "):
                adj[name].append(module)
    for u in module_type.keys():
        for v in adj[u]:
            if module_type.get(v, None) == con:
                inputs[v].append(u)
    last_pulse = {name: "low" for name in module_type.keys()}
    clicks = 10_000
    lcnt = hcnt = 0
    debug = [[] for _ in range(4)]
    state = {name: 0 for name, _ in module_type.items()}
    for i in range(clicks):
        if i == 1_000:  print("part 1:", lcnt * hcnt)
        in_queue = set([start])
        lcnt += 1
        queue = deque([(start, "low")])
        while queue:
            u, pulse = queue.popleft()
            if pulse == "low":
                lcnt += len(adj[u])
            else:
                hcnt += len(adj[u])
            for v in adj[u]:
                if v == "rx" and pulse == "low": print("part 2:", i)
                if module_type.get(v, None) == flop and pulse == "low":
                    state[v] ^= 1
                    if state[v] == 1: 
                        queue.append((v, "high"))
                        last_pulse[v] = "high"
                    else:
                        queue.append((v, "low"))
                        last_pulse[v] = "low"
                if module_type.get(v, None) == con:
                    if v == "ql":
                        for idx, node in enumerate(inputs[v]):
                            if last_pulse[node] == "high":
                                first[idx] = min(first[idx], i)
                        if all(v != math.inf for v in first): return 
                    if any(last_pulse[node] == "low" for node in inputs[v]):
                        queue.append((v, "high"))
                        last_pulse[v] = "high"
                    else:
                        queue.append((v, "low"))
                        last_pulse[v] = "low"
```

## Day 21: 

### Solution 1: 

```py
with open("big.txt", "r") as f:
    grid = [list(line) for line in f.read().splitlines()]
    R, C = len(grid), len(grid[0])
    neigborhood = lambda r, c: [(r + 1, c), (r, c + 1), (r - 1, c), (r, c - 1)]
    in_bounds = lambda r, c: 0 <= r < R and 0 <= c < C
    sr = sc = None
    for r, c in product(range(R), range(C)):
        if grid[r][c] == "S":
            sr, sc = r, c
    dist = [[math.inf] * C for _ in range(R)]
    queue = deque([(sr, sc, 0)])
    steps = 64
    # steps = 26501365
    while queue:
        r, c, d = queue.popleft()
        if dist[r][c] <= d: continue
        dist[r][c] = d
        for nr, nc in neigborhood(r, c):
            if not in_bounds(nr, nc) or grid[nr][nc] == "#": continue
            queue.append((nr, nc, d + 1))
    p1 = 0
    for r, c in product(range(R), range(C)):
        if dist[r][c] <= steps and dist[r][c] % 2 == steps % 2: p1 += 1
    print("part 1:", p1)
```

## Day 22: 

### Solution 1:  2d intersection, sets, bfs, queue

```py
coords = parse.compile("{:d},{:d},{:d}~{:d},{:d},{:d}")
with open("big.txt", "r") as f:
    bricks = sorted([list(coords.parse(line).fixed) for line in f.read().splitlines()], key = lambda x: x[2])
    def overlaps_1d(s1, s2, e1, e2):
        return min(e1, e2) - max(s1, s2) >= 0
    def overlaps_2d(brick1, brick2):
        return overlaps_1d(brick1[0], brick2[0], brick1[3], brick2[3]) and overlaps_1d(brick1[1], brick2[1], brick1[4], brick2[4])
    n = len(bricks)
    for i in range(n):
        max_z = 0
        for j in range(i):
            if overlaps_2d(bricks[i], bricks[j]):
                max_z = max(max_z, bricks[j][2], bricks[j][5])
        bricks[i][5] = bricks[i][5] - bricks[i][2] + max_z + 1
        bricks[i][2] = max_z + 1
    k_supports_v = [set() for _ in range(n)]
    v_supports_k = [set() for _ in range(n)]
    for i in range(n):
        for j in range(i):
            if overlaps_2d(bricks[i], bricks[j]) and bricks[i][2] == bricks[j][5] + 1:
                k_supports_v[j].add(i)
                v_supports_k[i].add(j)
    p1 = p2 = 0
    for i in range(n):
        if all(len(v_supports_k[j]) >= 2 for j in k_supports_v[i]): 
            p1 += 1
            continue
        queue = deque([i])
        fallen = set([i])
        while queue:
            u = queue.popleft()
            for v in k_supports_v[u]:
                if len(v_supports_k[v] - fallen) == 0 and v not in fallen:
                    fallen.add(v)
                    queue.append(v)
        p2 += len(fallen) - 1
    print("part 1:", p1)
    print("part 2:", p2)
```

## Day 23: 

### Solution 1:  compress the graph into about 30 vertex, then the np hard solution becomes feasible.  longest path is an np hard problem.

```py
with open("small.txt", "r") as f:
    grid = [list(line) for line in f.read().splitlines()]
    R, C = len(grid), len(grid[0])
    print(R, C)
    sr = sc = 0
    for c in range(C):
        if grid[0][c] == ".":
            sr, sc = 0, c
    queue = deque([(sr, sc, 0, 0, 0)])
    in_bounds = lambda r, c: 0 <= r < R and 0 <= c < C
    neighborhood = lambda r, c: [(r + 1, c), (r - 1, c), (r, c + 1), (r, c - 1)]
    p1 = 0
    while queue:
        r, c, steps, pr, pc = queue.popleft()
        if r == R - 1: p1 = max(p1, steps)
        for nr, nc in neighborhood(r, c):
            if grid[r][c] == ">" and nc <= c: continue
            if grid[r][c] == "v" and nr <= r: continue
            if not in_bounds(nr, nc) or (nr, nc) == (pr, pc) or grid[nr][nc] == "#": continue
            queue.append((nr, nc, steps + 1, r, c))
    print("part 1:", p1)
```

```py
with open("big.txt", "r") as f:
    grid = [list(line) for line in f.read().splitlines()]
    R, C = len(grid), len(grid[0])
    sr = sc = er = ec = 0
    for c in range(C):
        if grid[0][c] == ".":
            sr, sc = 0, c
        if grid[-1][c] == ".":
            er, ec = R - 1, c
    in_bounds = lambda r, c: 0 <= r < R and 0 <= c < C
    neighborhood = lambda r, c: [(r + 1, c), (r - 1, c), (r, c + 1), (r, c - 1)]
    vertices = {}
    for r, c in product(range(R), range(C)):
        if grid[r][c] == "#": continue
        nei_sum = sum(1 for nr, nc in neighborhood(r, c) if in_bounds(nr, nc) and grid[nr][nc] != "#")
        if nei_sum != 2:
            vertices[(r, c)] = len(vertices)
    n = len(vertices)
    stack = [(sr, sc, sr, sc, 0, 0)]
    adj = [[] for _ in range(n)]
    vis = set()
    while stack:
        r, c, pr, pc, u, w = stack.pop()
        if (r, c) in vertices and w > 0:
            v = vertices[(r, c)]
            adj[u].append((v, w))
            adj[v].append((u, w))
            u = v
            w = 0
        if (r, c) in vis: continue
        vis.add((r, c))
        for nr, nc in neighborhood(r, c):
            if not in_bounds(nr, nc) or (nr, nc) == (pr, pc) or grid[nr][nc] == "#": continue
            stack.append((nr, nc, r, c, u, w + 1))
    vis = [0] * n
    vis[0] = 1
    p2 = 0
    cur_w = 0
    def dfs(u):
        global cur_w, p2
        if u == n - 1:
            p2 = max(p2, cur_w)
            return
        for v, w in adj[u]:
            if vis[v]: continue
            cur_w += w
            vis[v] = 1
            dfs(v)
            cur_w -= w
            vis[v] = 0
    dfs(0)
    print("part 2:", p2)
```

## Day 24: 

### Solution 1:  linear algebra, vectors, 2d, system of nonlinear equations, sympy solver

```py
class Line:
    def __init__(self, m, b, px, py, vx, vy):
        self.m = m
        self.b = b
        self.px = px
        self.py = py
        self.vx = vx
        self.vy = vy
    def eval(self, x):
        return self.m * x + self.b
    def __repr__(self):
        return f"m = {self.m}, b = {self.b}, px = {self.px}, py = {self.py}"
hailstone = parse.compile("{:d}, {:d}, {:d} @ {:d}, {:d}, {:d}")
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    small, big = 200000000000000, 400000000000000
    hail = []
    for line in data:
        px, py, pz, vx, vy, vz = hailstone.parse(line).fixed
        m = vy / vx
        b = py - m * px
        hail.append(Line(m, b, px, py, vx, vy))
    p1 = 0
    n = len(hail)
    in_bounds = lambda x, y: small <= x <= big and small <= y <= big
    def intersection(l1, l2):
        if l1.m == l2.m: return 0, 0
        x = (l2.b - l1.b) / (l1.m - l2.m)
        y = l1.eval(x)
        return x, y
    def in_past(x, y, l):
        return (l.vx > 0 and x < l.px) or (l.vx < 0 and x > l.px) or (l.vy > 0 and y < l.py) or (l.vy < 0 and y > l.py)
    for i in range(n):
        for j in range(i + 1, n):
            x, y = intersection(hail[i], hail[j])
            if in_past(x, y, hail[i]) or in_past(x, y, hail[j]): continue
            if in_bounds(x, y): p1 += 1
    print(p1)
```

```py

hailstone = parse.compile("{:d}, {:d}, {:d} @ {:d}, {:d}, {:d}")
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    # small, big = 200000000000000, 400000000000000
    x_r, y_r, z_r, vx_r, vy_r, vz_r = sympy.symbols("x_r, y_r, z_r, vx_r, vy_r, vz_r")
    equations = []
    for line in data[:6]:
        px, py, pz, vx, vy, vz = hailstone.parse(line).fixed
        equations.append((px - x_r) * (vy_r - vy) - (py - y_r) * (vx_r - vx))
        equations.append((pz - z_r) * (vy_r - vy)  - (py - y_r) * (vz_r - vz))
    solution = sympy.solve(equations, [x_r, y_r, z_r, vx_r, vy_r, vz_r], dict = True)[0]
    p2 = sum(solution[var] for var in [x_r, y_r, z_r])
    print("part 2:", p2)
```

## Day 25: 

max flow min cut algorithms

### Solution 1:  undirected graph, connected components, disjoint set union

```py
net = Network(notebook = True)
net.from_nx(G)
net.show_buttons(filter_=['physics'])
net.show("small.html")
```

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    edges = []
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            edges.append((u, v))
    G = nx.Graph()
    G.add_nodes_from(nodes)
    G.add_edges_from(edges)
    G.remove_edges_from([("zjm", "zcp"), ("rfg", "jks"), ("nsk", "rsg")])
    p1 = math.prod(len(s) for s in nx.connected_components(G))
    print("part 1:", p1)
```

### Solution 2:  networkx minimum cut to partition into two disconnected graphs

minimum cut, until the cut value is 3, which means the maximum flow is equal to 3 with the current source and target node. 

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    edges = []
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            edges.append((u, v))
    nodes = list(nodes)
    G = nx.Graph()
    G.add_nodes_from(nodes)
    G.add_edges_from(edges, capacity = 1)
    u = nodes[0]
    for v in nodes[1:]:
        cut_value, partitions = nx.minimum_cut(G, u, v)
        if cut_value == 3: 
            print("part 1:", math.prod(len(p) for p in partitions))
            break
```

### Solution 3:  networkx minimum edge cut, 

it returns the edges to cut for minimum cut, so you just keep doing it until it is 3 edges that are cut.  In my test data set it happens in the first attempt

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    edges = []
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            edges.append((u, v))
    nodes = list(nodes)
    G = nx.Graph()
    G.add_nodes_from(nodes)
    G.add_edges_from(edges, capacity = 1)
    u = nodes[0]
    for v in nodes[1:]:
        cuts = nx.minimum_edge_cut(G, u, v)
        if len(cuts) == 3:
            G.remove_edges_from(cuts)
            print("part 1:", math.prod(map(len, nx.connected_components(G))))
            break
```

You can also do it without specifying the source and target node and it looks for the solution that disconnects the graph into two partitions with minimum cardinality for the edges.  So it finds the solution that cuts the fewest edges, since each edge represents capacity = 1.  This should be the three edges, so then just need to remove those edges.  Then it disconnected the graph and take the product of the connected components of the remaining graph.

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    edges = []
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            edges.append((u, v))
    G = nx.Graph()
    G.add_nodes_from(nodes)
    G.add_edges_from(edges, capacity = 1)
    cuts = nx.minimum_edge_cut(G)
    G.remove_edges_from(cuts)
    print("part 1:", math.prod(map(len, nx.connected_components(G))))
```

### Solution 4:  Stoer Wagner algorithm for global minimum cut

```py
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    edges = []
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            edges.append((u, v))
    G = nx.Graph()
    G.add_nodes_from(nodes)
    G.add_edges_from(edges, weight = 1)
    cut_value, partition = nx.stoer_wagner(G)
    print("part 1:", math.prod(map(len, partition)))
```

### Solution 5:  From Scratch Stoer Wagner Algorithm for global minimum cut

```py
def stoer_wagner(nodes, adj, edges):
    n = len(nodes)
    min_cut = math.inf
    connected_components = {node: [node] for node in nodes}
    partition_size = None
    prev = 0
    index_map = {node: i for i, node in enumerate(nodes)}
    vis = [0] * n
    for i in range(n - 1):
        # not necessarily random, and doesn't have to be
        u = prev
        while vis[u]: u += 1
        prev = u
        u = nodes[u]
        seen = set()
        weights = Counter()
        max_heap = []
        while len(seen) < n - i - 1:
            while max_heap and weights[max_heap[0][1]] != abs(max_heap[0][0]):
                heapq.heappop(max_heap)
            if max_heap:
                u = heapq.heappop(max_heap)[1]
                weights[u] = 0
            seen.add(u)
            for v in adj[u]:
                if v in seen: continue
                w = edges[(u, v)]
                weights[v] += w
                heapq.heappush(max_heap, (-weights[v], v))
        while max_heap and weights[max_heap[0][1]] != abs(max_heap[0][0]):
            heapq.heappop(max_heap)
        assert len(max_heap) > 0, "max heap is empty"
        wei, v = heapq.heappop(max_heap)
        wei = abs(wei)
        if wei < min_cut:
            min_cut = wei
            partition_size = len(connected_components[v])
        # contract v into u, merge into one connected component
        connected_components[u].extend(connected_components[v])
        # loop through children of v as w
        neighbors = adj[v]
        for w in neighbors:
            adj[w].remove(v)
            if w == u: continue
            if (u, w) not in edges:
                adj[u].add(w)
                adj[w].add(u)
            edges[(u, w)] += edges[(v, w)]
            edges[(w, u)] += edges[(w, v)]
        adj[v].clear()
        vis[index_map[v]] = 1
    return min_cut, partition_size

with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    adj = defaultdict(set)
    edges = Counter()
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            adj[u].add(v)
            adj[v].add(u)
            edges[(u, v)] = 1
            edges[(v, u)] = 1
            nodes.add(v)
    n = len(nodes)
    nodes = list(nodes)
    cut_value, partition_size = stoer_wagner(nodes, adj, edges)
    other_partition_size = n - partition_size
    print("part 1:", partition_size * other_partition_size)
```

```py
def stoer_wagner(nodes, adj, edges):
    contractions = []
    n = len(nodes)
    min_cut = math.inf
    best_phase = 0
    original_nodes = copy.deepcopy(nodes)
    # G = nx.Graph()
    # for (u, v), w in edges.items():
    #     G.add_edge(u, v, weight = w, label = str(w), title = str(w))
    # net = Network(notebook = True)
    # net.from_nx(G)
    # net.show_buttons(filter_=['physics'])
    # net.show(f"graph/small_0000.html")
    for i in range(n - 1):
        # not necessarily random, and doesn't have to be
        u = nodes.pop()
        nodes.add(u)
        seen = set()
        values = Counter()
        max_heap = []
        while len(seen) < n - i - 1:
            while max_heap and values[max_heap[0][1]] != abs(max_heap[0][0]):
                heapq.heappop(max_heap)
            if max_heap:
                u = heapq.heappop(max_heap)[1]
                values[u] = 0
            seen.add(u)
            for v in adj[u]:
                if v in seen or v not in nodes: continue
                w = edges[(u, v)]
                values[v] += w
                heapq.heappush(max_heap, (-values[v], v))
        while max_heap and values[max_heap[0][1]] != abs(max_heap[0][0]):
            heapq.heappop(max_heap)
        assert len(max_heap) > 0, "max heap is empty"
        wei, v = heapq.heappop(max_heap)
        wei = abs(wei)
        # print(values)
        # print("wei", wei, "v", v, "counter v", values[v])

        if wei < min_cut:
            min_cut = wei
            best_phase = i
        # contract v into u
        contractions.append((u, v))
        # loop through children of v as w
        for w in adj[v]:
            if w == u: continue
            if (u, w) not in edges:
                adj[u].append(w)
                adj[w].append(u)
            edges[(u, w)] += edges[(v, w)]
            edges[(w, u)] += edges[(w, v)]
            # print("u", u, "w", w, "edges", edges[(u, w)], edges[(w, u)])
        nodes.remove(v)
        # G = nx.Graph()
        # for u in nodes:
        #     for v in adj[u]:
        #         if v not in nodes: continue
        #         G.add_edge(u, v, weight = edges[(u, v)], label = str(edges[(u, v)]), title = str(edges[(u, v)]))
        # net = Network(notebook = True)
        # net.from_nx(G)
        # net.show_buttons(filter_=['physics'])
        # net.show(f"graph/small_{str(i + 1).zfill(4)}.html")
    p1, p2 = set(), set()
    for u, v in contractions[:best_phase]:
        p1.update((u, v))
    p2 = original_nodes - p1
    print(best_phase)
    return min_cut, [p1, p2]


with open("small.txt", "r") as f:
    data = f.read().splitlines()
    nodes = set()
    adj = defaultdict(list)
    edges = Counter()
    for line in data:
        u, nei_nodes = line.split(": ")
        nodes.add(u)
        for v in nei_nodes.split():
            adj[u].append(v)
            adj[v].append(u)
            edges[(u, v)] = 1
            edges[(v, u)] = 1
            nodes.add(v)
    cut_value, partition = stoer_wagner(nodes, adj, edges)
    print(cut_value, partition)
    # G = nx.Graph()
    # G.add_nodes_from(nodes)
    # G.add_edges_from(edges, weight = 1)
    # cut_value, partition = nx.stoer_wagner(G)
    print("part 1:", math.prod(map(len, partition)))
```

### Solution 6:  max flow min cut theorem, max flow with dinics algorithm, reconstruct partition by visiting all nodes from unsaturated edges.

```py
class FordFulkersonMaxFlow:
    """
    Ford-Fulkerson algorithm 
    - pluggable augmenting path finding algorithms
    - residual graph
    - bottleneck capacity
    """
    def __init__(self, n: int, edges: List[Tuple[int, int, int]]):
        self.size = n
        self.edges = edges
        self.cap = defaultdict(Counter)
        self.flow = defaultdict(Counter)
        self.adj_list = [[] for _ in range(self.size)]

    def build(self) -> None:
        self.delta = 0
        for src, dst, cap in self.edges:
            self.cap[src][dst] += cap
            self.adj_list[src].append(dst)
            self.adj_list[dst].append(src) # residual edge
            self.delta = max(self.delta, self.cap[src][dst])
        highest_bit_set = self.delta.bit_length() - 1
        self.delta = 1 << highest_bit_set

    def residual_capacity(self, src: int, dst: int) -> int:
        return self.cap[src][dst] - self.flow[src][dst]

    def main_dfs(self, source: int, sink: int) -> int:
        self.build()
        maxflow = 0
        while True:
            self.reset()
            cur_flow = self.dfs(source, sink, math.inf)
            if cur_flow == 0:
                break 
            maxflow += cur_flow
        return maxflow

    def neighborhood(self, node: int) -> List[int]:
        return (i for i in self.adj_list[node])

    def dinics_bfs(self, source: int, sink: int) -> bool:
        self.distances = [-1] * self.size
        self.distances[source] = 0
        queue = deque([source])
        while queue:
            node = queue.popleft()
            for nei in self.neighborhood(node):
                if self.distances[nei] == -1 and self.residual_capacity(node, nei) > 0:
                    self.distances[nei] = self.distances[node] + 1
                    queue.append(nei)
        return self.distances[sink] != -1

    def dinics_dfs(self, node: int, sink: int, flow: int) -> int:
        if flow == 0: return 0
        if node == sink: return flow
        while self.ptr[node] < len(self.adj_list[node]):
            nei = self.adj_list[node][self.ptr[node]]
            self.ptr[node] += 1
            if self.distances[nei] == self.distances[node] + 1 and self.residual_capacity(node, nei) > 0:
                cur_flow = self.dinics_dfs(nei, sink, min(flow, self.residual_capacity(node, nei)))
                if cur_flow > 0:
                    self.flow[node][nei] += cur_flow
                    self.flow[nei][node] -= cur_flow
                    return cur_flow
        return 0

    def main_dinics(self, source: int, sink: int) -> int:
        self.build()
        maxflow = 0
        while self.dinics_bfs(source, sink):
            self.ptr = [0] * self.size # pointer to the next edge to be processed (optimizes for dead ends)
            while True:
                cur_flow = self.dinics_dfs(source, sink, math.inf)
                if cur_flow == 0:
                    break
                maxflow += cur_flow
        return maxflow
with open("big.txt", "r") as f:
    data = f.read().splitlines()
    nodes = []
    index_map = {}
    edges = []
    for line in data:
        u, nei_nodes = line.split(": ")
        if u not in index_map:
            index_map[u] = len(index_map)
            nodes.append(u)
        for v in nei_nodes.split():
            if v not in index_map:
                index_map[v] = len(index_map)
                nodes.append(v)
            edges.append((index_map[u], index_map[v], 1))
            edges.append((index_map[v], index_map[u], 1))
    n = len(nodes)
    source = 0
    for sink in range(1, n):
        maxflow = FordFulkersonMaxFlow(n, edges)
        mf = maxflow.main_dinics(source, sink)
        if mf == 3:
            partition = set()
            queue = deque([source])
            while queue:
                u = queue.popleft()
                if u in partition: continue
                partition.add(u)
                for v in maxflow.adj_list[u]:
                    if maxflow.flow[u][v] < maxflow.cap[u][v]: queue.append(v)
            p1 = len(partition)
            p2 = n - p1
            print("part 1:", p1 * p2)
            break
```

### Solution 7:  Edmond's Karp Algorithm

```py

edmon```