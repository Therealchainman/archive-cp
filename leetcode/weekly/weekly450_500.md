# Leetcode Weekly Contest 450-499

# Leetcode Weekly Contest 450

## Minimum Swaps to Sort by Digit Sum

### Solution 1:  permutation cycles, swaps, disjoint sets

```cpp
struct Item {
    int dsum, val, idx;
    Item(int dsum, int val, int idx) : dsum(dsum), val(val), idx(idx) {}
    bool operator<(const Item &other) const {
        if (dsum != other.dsum) return dsum < other.dsum;
        return val < other.val;
    }
};
class Solution {
private:
    int digitSum(int x) {
        int ans = 0;
        while (x > 0) {
            ans += x % 10;
            x /= 10;
        }
        return ans;
    }
public:
    int minSwaps(vector<int>& nums) {
        int N = nums.size();
        vector<Item> arr;
        for (int i = 0; i < N; i++) {
            arr.emplace_back(digitSum(nums[i]), nums[i], i);
        }
        sort(arr.begin(), arr.end());
        vector<int> out(N, 0);
        vector<bool> vis(N, false);
        for (int i = 0; i < N; i++) {
            out[i] = arr[i].idx;
        }
        int ans = 0;
        for (int i = 0; i < N; i++) {
            if (vis[i]) continue;
            int sz = 0, u = i;
            while (!vis[u]) {
                vis[u] = true;
                sz++;
                u = out[u];
            }
            ans += sz - 1;
        }
        return ans;
    }
};
```

## Grid Teleportation Traversal

### Solution 1: 0-1 bfs, deque, distances

```cpp
const int INF = 1e9;
class Solution {
private:
    int R, C;
    vector<pair<int, int>> neighborhood(int r, int c) {
        return {{r - 1, c}, {r + 1, c}, {r, c - 1}, {r, c + 1}};
    }
    bool inBounds(int r, int c) {
        return r >= 0 && r < R && c >= 0 && c < C;
    }
    int decode(char ch) {
        return ch - 'A';
    }
public:
    int minMoves(vector<string>& grid) {
        R = grid.size(), C = grid[0].size();
        vector<vector<int>> dist(R, vector<int>(C, INF));
        vector<vector<bool>> vis(R, vector<bool>(C, false));
        dist[0][0] = 0;
        vector<vector<pair<int, int>>> portals(26);
        for (int r = 0; r < R; r++) {
            for (int c = 0; c < C; c++) {
                if (grid[r][c] >= 'A' && grid[r][c] <= 'Z') portals[decode(grid[r][c])].emplace_back(r, c);
            }
        }
        deque<pair<int, int>> dq;
        dq.emplace_back(0, 0);
        while (!dq.empty()) {
            auto [r, c] = dq.front();
            dq.pop_front();
            if (r == R - 1 && c == C - 1) return dist[r][c];
            for (auto [nr, nc] : neighborhood(r, c)) {
                if (!inBounds(nr, nc) || grid[nr][nc] == '#' || dist[r][c] + 1 >= dist[nr][nc]) continue;
                dist[nr][nc] = dist[r][c] + 1;
                dq.emplace_back(nr, nc);
            }
            if (grid[r][c] >= 'A' && grid[r][c] <= 'Z') {
                if (vis[r][c]) continue;
                vis[r][c] = true;
                for (auto [nr, nc] : portals[decode(grid[r][c])]) {
                    if (dist[r][c] < dist[nr][nc]) {
                        vis[nr][nc] = true;
                        dist[nr][nc] = dist[r][c];
                        dq.emplace_front(nr, nc);
                    }
                }
            }
        }
        return -1;
    }
};
```

## Minimum Weighted Subgraph With the Required Paths II

### Solution 1: minimum spanning tree of three nodes, three nodes, binary jumping, lca, depth, dfs, root distance


### Step 1: The Minimal Subtree
- In a tree, there's exactly one unique path between any pair of nodes.
- The minimal subtree `S` connecting nodes `{A, B, C}` is the **union** of the three simple paths:
  - `P_AB`: the path from A to B
  - `P_BC`: the path from B to C
  - `P_CA`: the path from C to A

This subtree `S` is connected and contains all nodes and edges needed to reach any of the three nodes from the others.

---

### Step 2: Consider Any Edge in the Subtree

Pick any edge `e` in `S`, with weight `w`.

Removing `e` splits the tree (and thus `S`) into two parts: say `X` and `Y`.

Since `S` contains exactly the nodes `{A, B, C}`, those nodes must be split between `X` and `Y`.

**Observation:**  
- One part must contain **exactly one** of the three nodes, and the other must contain the other two.
- For example, suppose:
  - `A` is in `X`
  - `B` and `C` are in `Y`

---

### Step 3: Count How Often `e` Is Used

In this situation:

- The path `A → B` **must** cross `e` → counted once
- The path `A → C` **must** cross `e` → counted again
- The path `B → C` stays entirely in `Y` → does **not** use `e`

So edge `e` is included in **exactly 2** of the 3 pairwise paths among `{A, B, C}`.

---

### Step 4: Generalize to All Edges

Every edge `e` in the minimal subtree `S` will separate one node from the other two (because the tree is acyclic and connected). So, **every edge in `S` is used in exactly 2 of the 3 distances**:

- `dist(A, B)`
- `dist(B, C)`
- `dist(C, A)`

Thus:

```cpp
struct Tree {
    int N, LOG;
    vector<vector<pair<int,int>>> adj;
    vector<int> depth, parent, dist;
    vector<vector<int>> up;

    Tree(int n) : N(n) {
        LOG = 20;
        adj.assign(N, vector<pair<int, int>>());
        depth.assign(N, 0);
        parent.assign(N, -1);
        dist.assign(N, 0);
        up.assign(LOG, vector<int>(N, -1));
    }
    void addEdge(int u, int v, int w = 1) {
        adj[u].emplace_back(v, w);
        adj[v].emplace_back(u, w);
    }
    void preprocess(int root = 0) {
        dfs(root);
        buildLiftingTable();
    }
    int kthAncestor(int u, int k) const {
        for (int i = 0; i < LOG && u != -1; i++) {
            if ((k >> i) & 1) {
                u = up[i][u];
            }
        }
        return u;
    }
    int lca(int u, int v) const {
        if (depth[u] < depth[v]) swap(u, v);
        // Bring u up to the same depth as v
        u = kthAncestor(u, depth[u] - depth[v]);
        if (u == v) return u;
        // Binary lift both
        for (int i = LOG - 1; i >= 0; i--) {
            if (up[i][u] != up[i][v]) {
                u = up[i][u];
                v = up[i][v];
            }
        }
        // Now parents are equal
        return parent[u];
    }
    int distance(int u, int v) const {
        int a = lca(u, v);
        return dist[u] + dist[v] - 2 * dist[a];
    }
private:
    void dfs(int u, int p = -1) {
        parent[u] = p;
        up[0][u] = p;
        for (auto &[v, w] : adj[u]) {
            if (v == p) continue;
            depth[v] = depth[u] + 1;
            dist[v] = dist[u] + w;
            dfs(v, u);
        }
    }
    void buildLiftingTable() {
        for (int i = 1; i < LOG; i++) {
            for (int j = 0; j < N; j++) {
                if (up[i - 1][j] == -1) continue;
                up[i][j] = up[i - 1][up[i - 1][j]];
            }
        }
    }
};
class Solution {
public:
    vector<int> minimumWeight(vector<vector<int>>& edges, vector<vector<int>>& queries) {
        int N = edges.size() + 1;
        Tree tree(N);
        for (const vector<int> &edge : edges) {
            int u = edge[0], v = edge[1], w = edge[2];
            tree.addEdge(u, v, w);
        }
        tree.preprocess();
        vector<int> ans;
        for (const vector<int> &query : queries) {
            int u = query[0], v = query[1], d = query[2];
            int du = tree.distance(u, d), dv = tree.distance(v, d), duv = tree.distance(u, v);
            int res = (du + dv + duv) / 2;
            ans.emplace_back(res);
        }
        return ans;
    }
};
```

# Leetcode Weekly Contest 451

## 3563. Lexicographically Smallest String After Adjacent Removals

### Solution 1: interval dp, lexicographically smallest

The algorithm uses 2D dynamic programming to mark erasable substrings and 1D DP to construct the optimal string.
The lexicographical optimization is greedy but bounded by valid erase operations.

Interval feasibility DP (canErase)
- Many string-erase or bracket-matching problems reduce to asking “can this substring be fully removed?” That’s a classic interval DP: build up from small intervals (length 2) to larger ones, checking:
- Direct removal (pair of characters),
- Nested removal (peel off outer pair and rely on inner),
- Concatenation (split into two erasable pieces).

Suffix optimization DP (dp)
- Once we know which substrings we’re free to drop, the remaining task reduces to “choose which erasable blocks to remove so that what’s left is lexicographically smallest.” That’s a linear DP over suffixes, where at each position you make the optimal local choice (erase or keep) and rely on already computed optimal answers for the remainder.

```cpp
class Solution {
private:
    int absDistance(char a, char b) {
        return abs(a - b);
    }
public:
    string lexicographicallySmallestString(string s) {
        int N = s.size();
        vector<vector<bool>> canErase(N + 1, vector<bool>(N + 1, false));
        for (int i = N - 1; i >= 0; i--) {
            for (int j = i + 1; j < N; j += 2) {
                int dist = absDistance(s[i], s[j]);
                if (dist == 1 || dist == 25) {
                    if (j - i + 1 == 2) canErase[i][j] = true;
                    else if (canErase[i + 1][j - 1]) canErase[i][j] = true;
                }
                for (int k = i + 1; k < j; k++) {
                    if (canErase[i][k] && canErase[k + 1][j]) canErase[i][j] = true;
                }
            }
        }
        vector<string> dp(N + 1);
        for (int i = N - 1; i >= 0; i--) {
            string ans = s.substr(i, N);
            for (int j = i; j < N; j++) {
                string cand = "";
                if (!canErase[i][j]) cand = s.substr(i, j - i + 1);
                cand += dp[j + 1];
                ans = min(ans, cand);
            }
            dp[i] = ans;
        }
        return dp[0];
    }
};
```

## 3562. Maximum Profit from Trading Stocks with Discounts

### Solution 1: knapsack convolution, tree shaped knapsack, dp on tree, dfs

## Overview

This algorithm addresses a **resource allocation problem** over a **hierarchical tree of projects**. Each node represents a project characterized by:

- **Cost** (current investment)  
- **Gain** (future return)

Given a **global budget constraint**, the goal is to **maximize total profit** by selectively investing in projects. Some projects may be executed at a **discounted cost**, and investments must respect **hierarchical dependencies**

---

## Key Concepts

### Tree Hierarchy  
Projects form a **rooted tree**, where investing in a project is only valid if its parent has already been processed (i.e., considered for investment). This enforces a top-down dependency structure.

### Dynamic Programming (DP)  
The algorithm performs a **bottom-up DP traversal** (via DFS), computing the optimal profit for each subtree for **all possible budget values** up to the given limit. Each node maintains a DP array where:

- `dp[b]` = maximum profit achievable in the subtree using `b` units of budget.

### Max-Plus Convolution  
To combine results from multiple child subtrees, the algorithm uses a **max-plus convolution**—a variation of the knapsack merge. This operation merges two DP arrays (from child subtrees), preserving the **best profit for every feasible budget split**.

### Discounted Investment  
Each project may optionally be undertaken at **half the original cost**, providing an extra decision branch per node. This adds flexibility in budget usage and can increase total returns.

---

## Algorithm Pillars

The approach rests on three main ideas:

1. **DFS on the Dependency Tree**  
   Traverse the project tree in post-order to ensure subproblems (child nodes) are solved before parent nodes.

2. **Knapsack-Style DP Arrays**  
   Each node maintains a DP array of size `B + 1`, where `B` is the total budget. The array stores the **maximum gain** for each budget level within its subtree.

3. **Merging via Max Convolution + Local Decision Step**  
   - Combine children's DP arrays using **max convolution** to explore all ways of splitting budget between subprojects.  
   - Apply a **local decision step**: for the current project, consider investing at full cost, discounted cost, or not at all, and update the DP accordingly.

---

## Max-Plus Convolution: When and Why?

Max convolution is critical when:

- Subtrees (subproblems) are **independent**  
- A **shared global constraint** (budget) applies  
- The objective is to **maximize/minimize** a quantity over all valid resource splits  
- Each subtree provides a DP table mapping `cost → best outcome`

In essence, it answers:

> "Given multiple DP arrays, how can we merge them optimally under a shared budget constraint?"

---

## Time Complexity

**O(N × B²)**, where:

- `N` is the number of nodes (projects)  
- `B` is the total budget

This is acceptable under typical constraints, especially with optimizations like pruning or efficient convolution techniques.

---

## Key Questions for Implementation

- **DFS DP**:  
  Can I perform DFS and compute a DP array at each node based on its children?

- **State Design**:  
  Do I need multiple DP states per node to track whether the parent was chosen?

- **Merging Strategy**:  
  Can child DP arrays be combined using a knapsack-like convolution?

```cpp
class Solution {
private:
    int RESOURCE_LIMIT;
    vector<vector<int>> adj;
    vector<int> costs, gains;
    vector<int> maxPlusConvolve(const vector<int> &A, const vector<int> &B) {
        vector<int> ans(RESOURCE_LIMIT + 1, 0);
        for (int i = 0; i <= RESOURCE_LIMIT; i++) {
            for (int j = 0; i + j <= RESOURCE_LIMIT; j++) {
                ans[i + j] = max(ans[i + j], A[i] + B[j]);
            }
        }
        return ans;
    }
    pair<vector<int>, vector<int>> dfs(int u) {
        vector<int> dp(RESOURCE_LIMIT + 1, 0), dpDiscounted(RESOURCE_LIMIT + 1, 0);
        for (int v : adj[u]) {
            auto [res, resDiscounted] = dfs(v);
            dp = maxPlusConvolve(dp, res);
            dpDiscounted = maxPlusConvolve(dpDiscounted, resDiscounted);
        }
        int cost = costs[u];
        for (int i = cost; i <= RESOURCE_LIMIT; i++) {
            dp[i] = max(dp[i], dpDiscounted[i - cost] + gains[u] - cost);
        }
        vector<int> ret = dp;
        cost >>= 1;
        for (int i = cost; i <= RESOURCE_LIMIT; i++) {
            ret[i] = max(ret[i], dpDiscounted[i - cost] + gains[u] - cost);
        }
        return {dp, ret};
    }
public:
    int maxProfit(int n, vector<int>& present, vector<int>& future, vector<vector<int>>& hierarchy, int budget) {
        RESOURCE_LIMIT = budget;
        costs = present;
        gains = future;
        adj.assign(n, vector<int>());
        for (const auto &edge : hierarchy) {
            int u = edge[0], v = edge[1];
            u--; v--;
            adj[u].emplace_back(v);
        }
        auto [ans, _] = dfs(0);
        return ans[budget];
    }
};
```

# Leetcode Weekly Contest 452

## 3567. Minimum Absolute Difference in Sliding Submatrix

### Solution 1: 2D sliding window, windowed computation, sorted set

sliding window over a matrix with local windowed computation using a sorted set to maintain the minimum absolute difference in a sliding submatrix.
Think about where the local variation between distinct values might be meaningful. 

This is not the most efficient algorithm, it is basically O(R * C * k^2), so for sufficiently large k, it will struggle.

```cpp
const int INF = (1LL << 31) - 1;
class Solution {
public:
    vector<vector<int>> minAbsDiff(vector<vector<int>>& grid, int k) {
        int R = grid.size(), C = grid[0].size();
        vector<vector<int>> ans(R - k + 1, vector<int>(C - k + 1, 0));
        for (int r = k - 1; r < R; r++) {
            for (int c = k - 1; c < C; c++) {
                set<int> pool;
                for (int i = r - k + 1; i <= r; i++) {
                    for (int j = c - k + 1; j <= c; j++) {
                        pool.insert(grid[i][j]);
                    }
                }
                if (pool.size() == 1) continue;
                int i = r - k + 1, j = c - k + 1;
                ans[i][j] = INF;
                for (auto it = pool.begin(), jt = next(pool.begin()); jt != pool.end(); it++, jt++) {
                    ans[i][j] = min(ans[i][j], abs(*jt - *it));
                }
            }
        }
        return ans;
    }
};
```

## 3568. Minimum Moves to Clean the Classroom

### Solution 1: constrained pathfinding, bfs, queue, bitmask, bitset

This is like a resource constrained pathfinding problem, it also shares some similarities with the travelling salesman problem on a grid, and steiner tree variants I suspect.

The main ingredient is really to figure out the states for the bfs to mark which are visited and make it optimal.

```cpp
struct State {
    int r, c, e, mask;
    State() {}
    State(int r, int c, int e, int mask) : r(r), c(c), e(e), mask(mask) {}
};
class Solution {
private:
    bitset<1024> vis[20][20][51];
    int targetIndex[20][20];
    int R, C;
    bool inBounds(int r, int c) {
        return r >= 0 && r < R && c >= 0 && c < C;
    }
    vector<pair<int, int>> neighborhood(int r, int c) {
        return {{r + 1, c}, {r - 1, c}, {r, c + 1}, {r, c - 1}};
    }
public:
    int minMoves(vector<string>& grid, int energy) {
        R = grid.size(), C = grid[0].size();
        int cnt = 0;
        fill(&targetIndex[0][0], &targetIndex[0][0] + 400, -1);
        memset(vis, false, sizeof(vis));
        queue<State> q;
        for (int r = 0; r < R; r++) {
            for (int c = 0; c < C; c++) {
                if (grid[r][c] == 'S') {
                    q.emplace(r, c, energy, 0);
                    vis[r][c][energy].set(0);
                } else if (grid[r][c] == 'L') {
                    targetIndex[r][c] = cnt++;
                }
            }
        }
        int endMask = (1 << cnt) - 1;
        int ans = 0;
        while (!q.empty()) {
            int sz = q.size(); 
            for (int i = 0; i < sz; i++) {
                State state = q.front();
                q.pop();
                if (state.mask == endMask) return ans;
                if (!state.e) continue;
                for (auto [nr, nc] : neighborhood(state.r, state.c)) {
                    if (!inBounds(nr, nc) || grid[nr][nc] == 'X') continue;
                    int nmask = state.mask, ne = state.e - 1;
                    if (grid[nr][nc] == 'L') {
                        nmask |= (1 << targetIndex[nr][nc]);
                    } else if (grid[nr][nc] == 'R') {
                        ne = energy;
                    }
                    if (vis[nr][nc][ne].test(nmask)) continue;
                    vis[nr][nc][ne].set(nmask);
                    q.emplace(nr, nc, ne, nmask);
                }
            }
            ans++;
        }
        return -1;
    }
};
```

## 3569. Maximize Count of Distinct Primes After Split

### Solution 1: lazy segment tree for range add updates and range max queries, track intervals for the first and last occurrence of each prime, online queries, prime sieve, sets



```cpp
// ----------------------------------------------------------------
//  SegmentTree supporting range‐add and range‐max queries
// ----------------------------------------------------------------
struct SegmentTree {
    int size;                         // internal size (next power of two)
    int neutral;               // neutral element for max (LLONG_MIN)
    vector<int> values;        // values[idx] = current max over idx’s segment, including operations[idx]
    vector<int> operations;    // operations[idx] = pending “add” for idx’s entire segment

    // Build a tree covering indices [0..n-1], initialized to all zeros.
    void init(int n) {
        neutral = 0;
        size = 1;
        while (size < n) size <<= 1;
        values.assign(2 * size, 0LL);
        operations.assign(2 * size, 0LL);
    }

    // Combine two lazy‐tags: here we do range‐addition, so tags combine by +.
    inline int modify_op(int x, int y) {
        return x + y;
    }

    // Combine two children’s values: we want range‐max.
    inline int calc_op(int x, int y) {
        return max(x, y);
    }

    // After changing values[idx] (and/or operations[idx]), climb up to the root
    // and fix every ancestor so that values[parent] = max(children) + operations[parent].
    void ascend(int idx) {
        while (idx > 0) {
            idx = (idx - 1) >> 1;          // move to parent
            int left_child  = 2 * idx + 1;
            int right_child = 2 * idx + 2;
            int combined = calc_op(values[left_child], values[right_child]);
            values[idx] = modify_op(combined, operations[idx]);
        }
    }

    // Add `val` to every element in [l..r] (0‐indexed, inclusive).
    void update(int l, int r, int val) {
        if (l > r) return;
        // We'll do an explicit stack‐based DFS over nodes
        // Each entry is (lx, rx, idx), meaning "node idx covers [lx..rx)"
        struct Node { int lx, rx, idx; };
        vector<Node> stack;
        stack.reserve(64);
        stack.emplace_back(0, size, 0);

        // Keep track of which nodes got a new “lazy” so we can ascend afterward
        vector<int> segments;
        while (!stack.empty()) {
            Node cur = stack.back();
            stack.pop_back();
            int lx = cur.lx, rx = cur.rx, idx = cur.idx;

            // 1) No overlap with [l..r]
            if (lx > r || rx - 1 < l) continue;

            // 2) Total cover: [lx..rx-1] ⊆ [l..r]
            if (lx >= l && rx - 1 <= r) {
                operations[idx] = modify_op(operations[idx], val);
                values[idx]     = modify_op(values[idx], val);
                segments.emplace_back(idx);
                continue;
            }

            // 3) Partial overlap: descend into children
            int mid = (lx + rx) >> 1;
            int left_child  = 2 * idx + 1;
            int right_child = 2 * idx + 2;
            // Left child covers [lx..mid), right covers [mid..rx)
            stack.emplace_back(lx,  mid, left_child);
            stack.emplace_back(mid,  rx,  right_child);
        }
        // Recompute ancestors of every changed node
        for (int idx : segments) {
            ascend(idx);
        }
    }

    // Query the maximum over [l..r] (0‐indexed, inclusive).
    int query(int l, int r) {
        if (l > r) return neutral;
        // We'll carry along a “carried_lazy” value which is the sum of all operations[]
        // from the root down to (but not including) the current node.
        struct QNode { int lx, rx, idx; int carry; };
        vector<QNode> stack;
        stack.reserve(64);
        stack.emplace_back(0, size, 0, 0LL);
        int result = neutral;

        while (!stack.empty()) {
            QNode cur = stack.back();
            stack.pop_back();
            int lx = cur.lx, rx = cur.rx, idx = cur.idx;
            int carried = cur.carry;

            // 1) No overlap
            if (lx > r || rx - 1 < l) continue;

            // 2) Total cover: [lx..rx-1] ⊆ [l..r]
            if (lx >= l && rx - 1 <= r) {
                int actual_val = modify_op(values[idx], carried);
                result = calc_op(result, actual_val);
                continue;
            }

            // 3) Partial overlap: descend into children,
            //    passing down “operations[idx]” plus the carried value.
            int mid = (lx + rx) >> 1;
            int left_child  = 2 * idx + 1;
            int right_child = 2 * idx + 2;
            int new_carry = modify_op(carried, operations[idx]);
            // Right child covers [mid..rx), left child covers [lx..mid)
            stack.emplace_back(mid,  rx,   right_child, new_carry);
            stack.emplace_back(lx,   mid,  left_child,  new_carry);
        }

        return result;
    }
};

const int MAXN = 1e5 + 5;
bool primes[MAXN];
int first[MAXN], last[MAXN];
set<int> sets[MAXN];

void sieve(int n) {
    fill(primes, primes + n, true);
    primes[0] = primes[1] = false;
    int p = 2;
    for (int p = 2; p * p <= n; p++) {
        if (primes[p]) {
            for (int i = p * p; i < n; i += p) {
                primes[i] = false;;
            }
        }
    }
}

class Solution {
private:
    void precompute() {
        sieve(MAXN);
        fill(first, first + MAXN, MAXN);
        fill(last, last + MAXN, -1);
        for (int i = 0; i < MAXN; i++) {
            sets[i].clear();
        }
    }
public:
    vector<int> maximumCount(vector<int>& nums, vector<vector<int>>& queries) {
        int N = nums.size(), M = queries.size();
        unordered_set<int> vis;
        SegmentTree seg;
        seg.init(N);
        precompute();
        for (int i = 0; i < N; i++) {
            if (!primes[nums[i]]) continue;
            sets[nums[i]].insert(i);
            vis.insert(nums[i]);
            first[nums[i]] = min(first[nums[i]], i);
            last[nums[i]] = i;
        }
        for (int p : vis) {
            seg.update(first[p], last[p] - 1, 1);
        }
        vector<int> ans(M, 0);
        for (int i = 0; i < M; i++) {
            int idx = queries[i][0];
            int val = nums[idx];
            // unset p at i
            if (primes[val]) {
                sets[val].erase(idx);
                if (idx == first[val] || idx == last[val]) {
                    seg.update(first[val], last[val] - 1, -1);
                }
                if (sets[val].empty()) {
                    first[val] = MAXN;
                    last[val] = -1;
                    vis.erase(val);
                } else if (idx == first[val]) {
                    auto it = sets[val].begin();
                    first[val] = *it;
                    seg.update(first[val], last[val] - 1, 1);
                } else if (idx == last[val]) {
                    auto it = sets[val].end();
                    last[val] = *prev(it);
                    seg.update(first[val], last[val] - 1, 1);
                }
            }
            // set p at i
            val = queries[i][1];
            nums[idx] = val;
            if (primes[val]) {
                sets[val].insert(idx);
                vis.insert(val);
                // how to handle when prime is not in array
                if (idx < first[val] || idx > last[val]) {
                    seg.update(first[val], last[val] - 1, -1);
                    first[val] = min(first[val], idx);
                    last[val] = max(last[val], idx);
                    seg.update(first[val], last[val] - 1, 1);
                }
            }
            int mx = seg.query(0, N - 2); // max overlap intervals
            ans[i] = vis.size() + mx;
        }
        return ans;
    }
};
```

# Leetcode Weekly Contest 453

## Count the Number of Computer Unlocking Permutations

### Solution 1: factorial permutations, number of permutations

```cpp
using int64 = int64_t;
const int MOD = 1e9 + 7;
class Solution {
public:
    int countPermutations(vector<int>& complexity) {
        int N = complexity.size(), ans = 1;
        for (int64 i = 1; i < N; i++) {
            ans = (ans * i) % MOD;
            if (complexity[i] <= complexity[0]) return 0;
        }
        return ans;
    }
};
```

## Count Partitions with Max-Min Different at Most K

### Solution 1: sliding window dp, deque, dynamic programming, prefix sum optimization of dp, monotonic queues

A constraint only on the max/min (or sum) of a subarray,
A desire to count or optimize over all subarrays ending at i,
And a need to aggregate DP values over a contiguous range of previous states—

```cpp
const int MOD = 1e9 + 7;
class Solution {
public:
    int countPartitions(vector<int>& nums, int k) {
        int N = nums.size();
        vector<int> dp(N + 1, 0), psum(N + 1, 0);
        dp[0] = psum[0] = 1;
        deque<int> minQ, maxQ;
        for (int i = 1, j = 0; i <= N; i++) {
            while (!minQ.empty() && nums[minQ.back()] >= nums[i - 1]) minQ.pop_back();
            while (!maxQ.empty() && nums[maxQ.back()] <= nums[i - 1]) maxQ.pop_back();
            minQ.emplace_back(i - 1); maxQ.emplace_back(i - 1);
            while (nums[maxQ.front()] - nums[minQ.front()] > k) {
                if (maxQ.front() == j) maxQ.pop_front();
                if (minQ.front() == j) minQ.pop_front();
                j++;
            }
            int cur = (psum[i - 1] - (j > 0 ? psum[j - 1] : 0) + MOD) % MOD;
            psum[i] = (psum[i - 1] + cur) % MOD;
            dp[i] = cur;
        }
        return dp.back();
    }
};
```

## Minimum Steps to Convert String with Operations

### Solution 1: 

```cpp

```

# Leetcode Weekly Contest 454

## Maximum Product of First and Last Element of a Subsequence

### Solution 1: prefix max/min, suffix max/min, fixed sized sliding window

```cpp
using int64 = int64_t;
const int64 INF = numeric_limits<int64>::max();
class Solution {
public:
    int64 maximumProduct(vector<int>& nums, int m) {
        int N = nums.size();
        int64 ans = -INF;
        int64 pmax = -INF, pmin = INF;
        vector<int64> smax(N, -INF), smin(N, INF);
        for (int i = N - 1; i >= 0; i--) {
            smax[i] = smin[i] = nums[i];
            if (i + 1 < N) {
                smax[i] = max(smax[i], smax[i + 1]);
                smin[i] = min(smin[i], smin[i + 1]);
            }
        }
        for (int i = 0; i + m - 1 < N; i++) {
            pmax = max(pmax, static_cast<int64>(nums[i]));
            pmin = min(pmin, static_cast<int64>(nums[i]));
            int64 cand1 = pmax * smax[i + m - 1];
            int64 cand2 = pmin * smin[i + m - 1];
            ans = max({ans, cand1, cand2});
        }
        return ans;
    }
};
```

## Find Weighted Median Node in Tree

### Solution 1: binary lifting, lca, median node, path sum

```cpp
using int64 = int64_t;
struct Tree {
    int N, LOG;
    vector<vector<pair<int,int>>> adj;
    vector<int> depth, parent;
    vector<int64> dist;
    vector<vector<int>> up;

    Tree(int n) : N(n) {
        LOG = 20;
        adj.assign(N, vector<pair<int, int>>());
        depth.assign(N, 0);
        parent.assign(N, -1);
        dist.assign(N, 0);
        up.assign(LOG, vector<int>(N, -1));

    }
    void addEdge(int u, int v, int w = 1) {
        adj[u].emplace_back(v, w);
        adj[v].emplace_back(u, w);
    }
    void preprocess(int root = 0) {
        dfs(root);
        buildLiftingTable();
    }
    int kthAncestor(int u, int k) const {
        for (int i = 0; i < LOG && u != -1; i++) {
            if ((k >> i) & 1) {
                u = up[i][u];
            }
        }
        return u;
    }
    int lca(int u, int v) const {
        if (depth[u] < depth[v]) swap(u, v);
        // Bring u up to the same depth as v
        u = kthAncestor(u, depth[u] - depth[v]);
        if (u == v) return u;
        // Binary lift both
        for (int i = LOG - 1; i >= 0; i--) {
            if (up[i][u] != up[i][v]) {
                u = up[i][u];
                v = up[i][v];
            }
        }
        // Now parents are equal
        return parent[u];
    }
    int query(int u, int v) const {
        int a = lca(u, v);
        int64 totalDist = distance(u, v, a);
        if (2LL * distance(u, a, a) >= totalDist && u != a) { // median node is in u -> a path
            int p = u;
            for (int k = LOG - 1; k >= 0; k--) {
                int cand = up[k][p];
                if (cand == -1) continue;
                if (depth[cand] >= depth[a] && 2LL * distance(u, cand, cand) < totalDist) p = cand;
            }
            return up[0][p];
        } 
        int p = v;
        for (int k = LOG - 1; k >= 0; k--) {
            int cand = up[k][p];
            if (cand == -1) continue;
            if (depth[cand] >= depth[a] && 2LL * distance(v, cand, cand) <= totalDist) p = cand;
        }
        return p;
    }
    int64 distance(int u, int v, int a) const {
        return dist[u] + dist[v] - 2 * dist[a];
    }
private:
    void dfs(int u, int p = -1) {
        parent[u] = p;
        up[0][u] = p;
        for (auto &[v, w] : adj[u]) {
            if (v == p) continue;
            depth[v] = depth[u] + 1;
            dist[v] = dist[u] + w;
            dfs(v, u);
        }
    }
    void buildLiftingTable() {
        for (int i = 1; i < LOG; i++) {
            for (int j = 0; j < N; j++) {
                if (up[i - 1][j] == -1) continue;
                up[i][j] = up[i - 1][up[i - 1][j]];
            }
        }
    }
};
class Solution {
public:
    vector<int> findMedian(int n, vector<vector<int>>& edges, vector<vector<int>>& queries) {
        int M = queries.size();
        Tree tree(n);
        for (const auto &edge : edges) {
            int u = edge[0], v = edge[1], w = edge[2];
            tree.addEdge(u, v, w);
        }
        tree.preprocess();
        vector<int> ans;
        for (const auto &query : queries) {
            int u = query[0], v = query[1];
            ans.emplace_back(tree.query(u, v));
        }
        return ans;
    }
};
```

# Leetcode Weekly Contest 455

## Inverse Coin Change

### Solution 1: dynamic programming, combinatorics

```cpp
class Solution {
public:
    vector<int> findCoins(vector<int>& numWays) {
        int N = numWays.size();
        vector<int> ans, dp(N + 1, 0);
        dp[0] = 1;
        for (int d = 1; d <= N; d++) {
            if (dp[d] > numWays[d - 1]) return {};
            if (dp[d] == numWays[d - 1]) continue;
            if (numWays[d - 1] - dp[d] != 1) return {};
            ans.emplace_back(d);
            for (int i = d; i <= N; i++) {
                dp[i] += dp[i - d];
            }
        }
        return ans;
    }
};
```

## Minimum Increments to Equalize Leaf Paths

### Solution 1: undirected tree, dfs, root-to-leaf path sum

```cpp
using int64 = int64_t;
const int64 INF = numeric_limits<int64>::max();
class Solution {
private:
    int64 maxSum = 0;
    int ans = 0;
    vector<int> C;
    vector<vector<int>> adj;
    void dfs1(int u, int p = -1, int64 sum = 0) {
        sum += C[u];
        bool isLeaf = true;
        for (int v : adj[u]) {
            if (v == p) continue;
            dfs1(v, u, sum);
            isLeaf = false;
        }
        maxSum = max(maxSum, sum);
    }
    int64 dfs2(int u, int p = -1, int64 sum = 0) {
        int64 minDelta = INF, minCount = 0;
        sum += C[u];
        bool isLeaf = true;
        for (int v : adj[u]) {
            if (v == p) continue;
            int delta = dfs2(v, u, sum);
            if (delta < minDelta) {
                minDelta = delta;
                minCount = 0;
            }
            if (delta == minDelta) minCount++;
            isLeaf = false;
        }
        if (isLeaf) minDelta = maxSum - sum;
        if (!minDelta) return 0;
        ans = (ans - minCount + 1);
        return minDelta;
    }
public:
    int minIncrease(int n, vector<vector<int>>& edges, vector<int>& cost) {
        adj.assign(n, vector<int>());
        for (const auto &edge : edges) {
            int u = edge[0], v = edge[1];
            adj[u].emplace_back(v);
            adj[v].emplace_back(u);
        }
        C = vector<int>(cost.begin(), cost.end());
        dfs1(0);
        dfs2(0);
        return ans;
    }
};
```

## Minimum Time to Transport All Individuals

### Solution 1:  state graph, dijkstra, minheap, bitmask, enumerate submasks

```cpp
using int64 = int64_t;
const long double INF = numeric_limits<long double>::max();
struct State {
    int mask, stage, side;
    long double t;
    State() {}
    State(int mask, int stage, int side, long double t) : mask(mask), stage(stage), side(side), t(t) {}
    bool operator<(const State& other) const {
        return other.t < t;
    }
};
class Solution {
public:
    double minTime(int n, int k, int m, vector<int>& time, vector<double>& mul) {
        if (n > 1 && k == 1) return -1;
        vector<int> subsetMax(1 << n, 0);
        for (int mask = 0; mask < (1 << n); mask++) {
            int mx = 0;
            for (int i = 0; i < n; i++) {
                if ((mask >> i) & 1) {
                    mx = max(mx, time[i]);
                }
            }
            subsetMax[mask] = mx;
        }
        int endMask = (1 << n) - 1;
        vector<vector<vector<long double>>> dist(1 << n, vector<vector<long double>>(m, vector<long double>(2, INF)));
        priority_queue<State> minheap;
        dist[0][0][0] = 0;
        minheap.emplace(0, 0, 0, 0);
        while (!minheap.empty()) {
            State st = minheap.top();
            minheap.pop();
            if (st.t > dist[st.mask][st.stage][st.side]) continue;
            if (st.mask == endMask && st.side == 1) return st.t;
            if (st.side == 0) { // right side
                int remMask = st.mask ^ endMask;
                for (int submask = remMask; submask > 0; submask = (submask - 1) & remMask) {
                    if (__builtin_popcount(submask) > k) continue;
                    int t = subsetMax[submask];
                    long double ncost = t * mul[st.stage];
                    int nstage = (st.stage + static_cast<int64>(floor(ncost)) % m) % m;
                    int nmask = st.mask | submask;
                    long double nTime = st.t + ncost;
                    if (nTime < dist[nmask][nstage][1]) {
                        dist[nmask][nstage][1] = nTime;
                        minheap.emplace(nmask, nstage, 1, nTime);
                    }
                }
            } else {
                for (int r = 0; r < n; r++) {
                    if (!((st.mask >> r) & 1)) continue;
                    int t = subsetMax[1 << r];
                    long double ncost = t * mul[st.stage];
                    int nstage = (st.stage + static_cast<int64>(floor(ncost)) % m) % m;
                    int nmask = st.mask ^ (1 << r);
                    long double nTime = st.t + ncost;
                    if (nTime < dist[nmask][nstage][0]) {
                        dist[nmask][nstage][0] = nTime;
                        minheap.emplace(nmask, nstage, 0, nTime);
                    }
                }
            }
        }
        return -1;
    }
};
```

# Leetcode Weekly Contest 456

## 

### Solution 1: 

```cpp

```